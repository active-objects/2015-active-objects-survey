% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

\documentclass[prodmode,acmtecs]{acmsmall} % Aptara syntax

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\usepackage{tikz}
\usepackage[normalem]{ulem}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{parcolumns}
\usepackage{listings,multicol,amssymb}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}
\usepackage{listings}
\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\TODO}[1]{\textcolor{red}{\textbf{[TODO:#1]}}}
\newcommand{\NOTE}[1]{\textcolor{blue}{\textbf{[Note:#1]}}}
\newcommand{\LUDO}[1]{\textcolor{blue}{\textbf{[Ludo:#1]}}}
\newcommand{\KIKO}[1]{\textcolor{cyan}{\textbf{[Kiko:#1]}}}
\newcommand{\TW}[1]{\textcolor{magenta}{\textbf{[Tobias:#1]}}}
\newcommand{\JS}[1]{\textcolor{gray}{\textbf{[Justine:#1]}}}
\newcommand{\VLAD}[1]{\textcolor{orange}{\textbf{[Vlad:#1]}}}
\newcommand{\parT}{\texttt{ParT}}

%% For bold syntax highlighting in the Encore chapter
\renewcommand{\ttdefault}{lmtt}
\DeclareFontFamily{T1}{lmtt}{}
\DeclareFontShape{T1}{lmtt}{m}{n}{<-> ec-lmtl10}{}
\DeclareFontShape{T1}{lmtt}{m}{\itdefault}{<-> ec-lmtlo10}{}
\DeclareFontShape{T1}{lmtt}{\bfdefault}{n}{<-> ec-lmtk10}{}
\DeclareFontShape{T1}{lmtt}{\bfdefault}{\itdefault}{<-> ec-lmtko10}{}


% Metadata Information
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}


% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\doi{0000001.0000001}

%ISSN
%\issn{1234-56789}

% Document starts
\begin{document}

% Page heads
%\markboth{G. Zhou et al.}{A Multifrequency MAC Specially Designed for WSN Applications}

% Title portion
\title{A Survey of Active Objects and Actors}
\author{To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}}
% NOTE! Affiliations placed here should be for the institution where the
%       BULK of the research was done. If the author has gone to a new
%       institution, before publication, the (above) affiliation should NOT be changed.
%       The authors 'current' address may be given in the "Author's addresses:" block 
%(below).
%       So for example, Mr. Abdelzaher, the bulk of the research was done at UIUC, and he 
%is
%       currently affiliated with NASA.

\begin{abstract}
the abstract
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
%\begin{CCSXML}
%<ccs2012>
% <concept>
%  <concept_id>10010520.10010553.10010562</concept_id>
%  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%  <concept_significance>500</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010575.10010755</concept_id>
%  <concept_desc>Computer systems organization~Redundancy</concept_desc>
%  <concept_significance>300</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010553.10010554</concept_id>
%  <concept_desc>Computer systems organization~Robotics</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
% <concept>
%  <concept_id>10003033.10003083.10003095</concept_id>
%  <concept_desc>Networks~Network reliability</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
%</ccs2012>  
%\end{CCSXML}

%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

%
% End generated code
%

% We no longer use \terms command
%\terms{Design, Algorithms, Performance}

\keywords{Active objects, actors, concurrency, distributed systems}

%\acmformat{Gang Zhou, Yafeng Wu, Ting Yan, Tian He, Chengdu Huang, John A. Stankovic,
%and Tarek F. Abdelzaher, 2010. A multifrequency MAC specially
%designed for  wireless sensor network applications.}
% At a minimum you need to supply the author names, year and a title.
% IMPORTANT:
% Full first names whenever they are known, surname last, followed by a period.
% In the case of two authors, 'and' is placed between them.
% In the case of three or more authors, the serial comma is used, that is, all author 
%names
% except the last one but including the penultimate author's name are followed by a comma,
% and then 'and' is placed before the final author's name.
% If only first and middle initials are known, then each initial
% is followed by a period and they are separated by a space.
% The remaining information (journal title, volume, article number, date, etc.) is 
%'auto-generated'.

%\begin{bottomstuff}
%This work is supported by the National Science Foundation, under
%grant CNS-0435060, grant CCR-0325197 and grant EN-CS-0329609.
%
%Author's addresses: G. Zhou, Computer Science Department,
%College of William and Mary; Y. Wu  {and} J. A. Stankovic,
%Computer Science Department, University of Virginia; T. Yan,
%Eaton Innovation Center; T. He, Computer Science Department,
%University of Minnesota; C. Huang, Google; T. F. Abdelzaher,
%(Current address) NASA Ames Research Center, Moffett Field, California 94035.
%\end{bottomstuff}

\maketitle


\TODO{TODO LIST}



\NOTE{Page limit is 35 pages}


\section{Introduction}

A global introduction to the common problems in programming distributed systems. Safety 
issues, common bugs and efficiency issues. A first overview of the families of 
programming models for concurrent and distributed systems. What is difficult? What 
features are important in concurrent? in distributed systems?


\section{Active object Languages}

\subsection{An historical view of Actor and active-object languages}

We present the languages discussed in this overview paper in a
historical context.  The general development of high-level programming
languages is driven by the quest for suitable abstractions of the
low-level implementation details of the specific underlying hardware
architectures, i.e., machine instructions.  The basic abstraction of
the machine instructions for reading from and writing to memory
locations which underlies imperative programming is the
assignment. The low-level flow of control is further abstracted by
means of high-level structuring mechanisms which allow the
construction of a program in a compositional manner, e.g., sequential
composition, choice and iterative constructs.

One of the first major high-level imperative programming languages is
ALGOL (short for ALGOrithmic Language) \cite{backus63cacm} which
features procedural and functional abstractions of data and control.
The resulting general abstraction level allows for a compositional
construction and analysis of mainly the flow of control.  A major
advance in the development of high-level programming languages which
gave rise to the paradigm of object-orientation is the compositional
construction of programs in terms of modules.  Modules are used to
model abstract data types and as such provide a powerful abstraction
which fully integrates data and control.  In the object-oriented
programming paradigm modules are generalized to classes.  Classes can
be characterized as modules from which objects can be dynamically
instantiated and referred to by unique identifiers (generated at
runtime).  The concepts of classes and objects were introduced in
Simula 67 \cite{dahl66cacm}, the first object-oriented
language. Whereas Simula was a sequential language with a single
thread of control, it was developed to simulate real-world
(concurrent) systems and featured the concept of \emph{coroutines}
\cite{dahl68simula}.

A major remaining challenge in the development of high-level
programming languages is the high-level specification of concurrent
and parallel threads of control and their synchronization.  In process
calculi like CSP \cite{Hoare85} and CCS \cite{Milner89}
independent threads of control communicate data synchronously, e.g.,
via channels.  The Ada programming language \cite{bal89acmsurv}
extends this model of synchronous communication by a rendez-vous
interpretation of the execution of procedure calls and returns.  In
the shared-variable model of concurrency, threads of control
communicate and synchronize directly via shared data. For example in
the popular object-oriented language Java \cite{goetz06java} such a
thread of control consists of a stack of procedure (method) calls,
extending the sequential thread of control of Simula and Smalltalk
from one to multiple threads in an manner resembling operating
systems.

The shared-variable model of concurrency underlying the Java language
requires that the developer ensures so-called ``thread safety'';
without enough synchronization, data races between threads make the
program behavior ``unpredictable and sometimes surprising''
\cite{goetz06java}. 
To avoid races, complex low-level synchronization
mechanisms are required which may in turn give rise to deadlocks and
thread starvation.  The execution of multithreaded programs depends on
an underlying, intricate, and fine-grained granularity of
interleaving, which makes multithreaded programs very difficult to
understand and verify.  Further, since data, as represented statically
by classes, and control, as represented at run-time by threads, are
decoupled, this model of concurrency is also unintuitive and
difficult to use in a distributed setting.


In contrast to the above synchronous communication mechanisms, the
Actor model of computation \cite{Agha86-book} is based on loosely
coupled processes and asynchronous message passing.  Actors integrate
and encapsulate both data and a single thread of control, and
communicate without transfer of control. Message delivery is
guaranteed but messages may arrive out of order.  This loose coupling
makes Actor languages conceptually attractive for distributed
programming. 
Erlang~\cite{Erlang-book} is one of the most successful actor language, especially 
because of its adoption by programmers in the industry, and because of its massively 
parallel execution model supporting  a huge number of independent actors. 
 Active objects integrate the basic Actor model with
object-oriented concepts. This integration can be realized by
modelling a message as an asynchronous method call, thus fixing the
interpretation of a message by a corresponding method definition. 
 In
 Rebeca \cite{DBLP:conf/csicc/SirjaniMM01,DBLP:journals/jucs/SirjaniBM05} 
the methods are run to completion without any
further synchronization mechanism and do not return values. Like in
the original Actor model, returning values from a method call can be
modelled by another asynchronous message;
%Rebeca is an 
%actor-based language with a FIFO point-to-point communication and message service. 
%Actors are encapsulated units of concurrency, with no shared variables. Communication takes place by asynchronous message passing, with non-blocking send and receive statements. 
%In Rebeca, computation is message-driven, a message is taken from the top of the message 
%queue and is executed non-preemptively. In addition, instead of having a soup of 
%messages 
%like in Agha's actor model, 
unlike the original Actor model, in Rebeca the order of messages between any two actors is 
preserved. 
%A network where messages can be lost or arrive out-of-order, can be modeled using an 
%actor that behaves like the intermediate medium. The same as the original actor mode, 
%``while'' loops or periodic events are modeled by sending messages to itself. 
 % Based on the application 
%domains, where necessary, Rebeca is extended to provide other means of communication or 
%safe synchronization.
% \sout{In contrast to how Erlang and Rebeca process asynchronous messages on the callee 
%side,
%The Actor-based extension of Scala \cite{haller2009scala} introduces pattern matching on 
%the callee side t interpret and filter messages.}
% \KIKO{I have modified the sentence, although I believe that this last sentence is
% that important and introduces one aspect of Scala which is never mentioned it again.
% I am missing a bit the reason of the comparison}
 
Rebeca is 
designed to be simple and analyzable. Efficient compositional verification 
\cite{DBLP:journals/jucs/SirjaniMSB05} and specific state space reduction techniques 
\cite{DBLP:journals/acta/JaghooriSMKM10}  are created based on the following 
characteristics of the model: no shared variable, no blocking send or receive, 
single-threaded actors, and non-preemptive execution of each message (execution of a 
message  will not 
interfere with  execution of another one).

Pushing the notion of method calls further by directly supporting
return values leads to the notion of future variables.  Futures were
originally discovered by Baker and Hewitt in the
70s~\cite{BakerHH77}, and later rediscovered by Liskov and
Shrira as promises in Argus~\cite{Liskov88} and by Halstead in the
context of MultiLisp~\cite{Halstead:1985:MLC:4472.4478} before finding their way
into object-oriented languages such as
Concurrent\-Smalltalk~\cite{Yokote87}, ABCL~\cite{Yonezawa:1986:OCP:28697.28722},
Eiffel$/\!/$~\cite{Caromel96}, and CJava~\cite{Cugola97}. A future may
be understood as a mailbox which will eventually contain the return
values from a method call. Thus the calling method may proceed with
its computation and pick up the reply later. However, this requires
additional synchronization by means of a blocking get-operation on the
future.

In Creol \cite{johnsen03nik,johnsen07sosym} a powerful further
synchronization mechanism is provided by cooperative scheduling of the
methods of an active object by an explicit statement which allows the
release of control.  This gives rise to a coroutine like execution of
the method activations of an active object which encapsulates a single
thread of control. This model of computation supports a compositional
proof theory \cite{deBoerDJ07}.


Caromel, Henrio, and Serpette~\cite{CHS:POPL04} present ASP, an
imperative, asynchronous object calculus with transparent futures.
Their active objects may have internal passive objects which can be
passed between active objects by first deep copying the entire
(passive) object graph.  To manage the complexity of reasoning about
distributed and concurrent systems, they restrict the language to
ensure that reduction is confluent and deterministic. ASP constitutes
the theoretical foundation for the ProActive language
\cite{CH-book}.
Later, ownership type systems have been proposed to
alleviate unnecessary copying of passive objects \cite{clarke08aplas}. 

The Java multithreaded model of computation can be integrated with
active objects. In the Abstract Behavioral Specification Language ABS
\cite{JHSSS10} this is done by combining Creol's cooperative
scheduling model with the structuring mechanism of concurrent object
groups (cogs) \cite{SchaeferP10b}.  Such a group of active objects
consists of a pool of threads each of which is generated from an
external asynchronous call and extended as a stack of internal
synchronous method calls.  Within such a pool only one thread is
executing at a time, but the granularity of interleaving is fully
controlled by the high-level release statements of the cooperative
scheduling.

Another approach on integrating active objects in object-oriented languages is
taken by the Encore \cite{ref:encore} programming language which,
as ASP, makes a distinction between active and passive objects --
passive objects are owned by active objects.
%
However, unlike ASP, 
passive objects are passed by reference and are data race free
via a capability type system~\cite{encore:kappa}.
%
%Both the Encore \cite{ref:encore} and the ProActive languages
%support the distinction between active and passive objects. Passive
%objects are associated to (or owned by) active objects. In terms of sharing,
%ProActive follows a deep copying strategy which prevents data races
%while, in Encore, passive objects are passed by reference and a
%capability type system prevents data races.
%is no sharing of passive objects between active objects (when
%communicated passive objects are copied), no data races occur, in
%contrast to the multithreaded control of the cogs in ABS. 

All these languages have drawn attention on different areas.
%
For instance, ABS is an executable modelling language with a focus on analysis and
property-preserving code generation while, both Encore and ProActive, aim at
efficient runtime systems for active object languages where
Encore targets multicore platforms and ProActive has also been applied for the
distributed setting.

\paragraph{Further interesting languages}

In parallel with this track of languages, other languages emerged, diverging more from 
the classical active-object model. 
JAC~\cite{ref:jac} stands for Java Annotations for Concurrency, it relies on a set of 
Java annotation allowing the programmer to specify what parallelism can occur inside a 
Java object with a relatively high-level perspective. It is also possible to encode some 
kinds of actors in JAC. AmbientTalk~\cite{Dedecker:2006:APA:2171327.2171349} provide 
actors with fully asynchronous futures: contrarily to other active object languages, 
futures do not provide a classical synchronisation pattern,  instead a call on a 
future triggers an asynchronous invocation that will be executed when the future is 
available.




Plus a small (or bigger) note on : 
E programming language, 
Kilim, Akka, Go,
\TODO{Reiner: Panini}
\TODO{Not sure all of them should be cited but we will decide later}




\subsection{Dimensions of Comparison between Languages}
Before presenting in details different active object languages, we  
define the key points that we consider as important regarding the design of actor 
programming languages. 
%Those dimensions of comparison will  be used in the following to present 
%the different languages.

\paragraph{Objective of the language} Identifying the objective of the language, for
which purpose it was created, is crucial to understand the design of a programming 
language and the trade-offs that had to be taken between different aspects.  For example, 
the performance of the language can be a crucial factor 
for which another aspect can be neglected, such as the accessibility of the language to 
non-experts. %Also, a high expressiveness can be expected for a language targeting 
%several 
%platforms. 
%Having a precise objective for a language generally defines the trade-offs 
%that have to be taken between 
%several aspects. 
%and for this reason, 
%in the following each language description 
%will start by a brief presentation of the language's objectives.

\paragraph{Degree of synchronisation} 
	The way a concurrent programming language is  designed highly 
	depends on the degree of synchronisation that can be expressed in it. Each language has a 
	different set of synchronisation primitives, although for active object languages, 
	there is a narrow set of such primitives. In some languages, inspired from pure actors, there is no synchronisation primitive: concurrent entities evolve in a completely 
	asynchronous manner and there is no particular instruction waiting for some event to happen. The 
	only synchronisation between processes is due to the causal dependency created by the 
	flow of messages. 
%	In this case, a forged synchronisation 
%	can be obtained by choosing the set of messages an actor can handle at a given point 
%	in time. 
	On the other hand, many active object languages use futures as a synchronisation 
	mechanism. 
	A future represents a
	result that has not been computed yet. When the result is computed, it can be 
	automatically available or explicitly retrieved, depending on the language design; we then say that the
	future is \emph{resolved}. A process can also block waiting for a future to be resolved.
	In active object languages, futures represent the result of asynchronous 
	invocations. In most of those languages, an access to a future is a  
	synchronisation point. Somehow such a synchronisation makes 
	programming easier as it keeps a sequential workflow that the programmer can trust.
	Several active object languages also support cooperative scheduling: a thread can be 
	suspended to handle another message, and resumed later. The suspension can be 
	triggered when checking whether a future
	is resolved or not. This breaks the sequential processing of a message, but also 
	allows 
	programs to be more efficient and less deadlock-prone.

	\paragraph{Degree of transparency} Another difference between languages 
	is the number and the complexity of the programming abstractions the programmer has 
	to 
	know; among them some are explicitly visible in the program and some are 
	hidden: they are transparent. For example,  if futures are transparent
	variables which contain futures are not explicitly distinguished with a special 
	static type, additionally there is no 
	explicit instruction for accessing a future: an access to a future object is blocking 
	if the future is not resolved yet.
%some active object languages 
%feature transparent asynchronous method invocations, i.e. asynchronous method 
%invocations that are 
%syntactically identical to synchronous ones. S
	In general, the more transparency, the easier it is to write 	simple programs, 
	because the programmer do not need to know all the intricacies of the 
	programming model and because parallelism can be provided automatically. However, for
	complex programs, the benefits of transparency is weakened, as exposing 
	the programmer to the programming abstractions that are used can make 
	programming, debugging,
	or optimization easier. 
	

	\paragraph{Degree of data sharing} Data sharing is a crucial aspect of concurrent and 
	distributed programming. Depending on the target application domain and the potential 
	for distributed execution, the constraints regarding data sharing can be vary a lot 
	and be stronger or weaker. 		
	The most efficient way to communicate data between 
	different cores of the same machine is to share the data, whether in a distributed 
	setting, copying the information to the different consumers of the data is often more
	efficient as it avoids additional communications for peaking the data source. 	
	Aside efficiency, the complexity of the language implementation varies 	
	accordingly to the degree of data sharing. For example, copying data raises the 
	problem of 
	data consistency as data modifications may not be reflected on all copies.  
	But on the other hand, shared data access involves additional communication to the 
	shared memory, and additional synchronisation and delays. In practice, active object 
	and actor languages that have distributed runtimes often use a ``no shared memory'' 
	approach that favors 	
	data copies for objects, and that accepts a few entities that are globally 
	known and shared. On the contrary, when all objects are shared and accessible from 
	anywhere, the data consistency is simpler to obtain, but 
	the communication overhead is higher in distributed 
	settings. 
	%Encore is probably the richest language from this point of view, aiming at a 
	%precise control of data sharing including entities that can explicitly be shared 
	%between different actors.

	\paragraph{Formal semantics and support} To reason on the 
	properties of a language, a formal semantics is required. Most of the 
	active object languages have a well-defined formal semantics; this is probably due to 
	the fact that  active object and actor models were designed to make concurrent 
	entities run safer. Formal semantics 
	can then be used in several ways, either to prove generic properties that makes 
	programming easier, or to prove the correctness of some 
	implementation or some optimisations, or to implement formal tools for the analysis 
	of programs. A language that has a formal semantics is overall more 
	trustworthy; this is why we  take this point 
	of comparison into account. 
	
	\paragraph{Implementation and tooling support} We believe it is important to 
	compare the active object languages relatively to the  tools they 
	provide. Indeed, the implementation of an active object language and of the 
	associated tools is also a factor to 
	take into account because it might explain some constraints related to the underlying 
	technologies that are used. Finally, the tooling support 
	around a programming language ranges from utilities to help the programmer 
	designing, writing, and 
	analysing their programs, to utilities to support the deployment and execution of these 
	programs. This point of comparison and the previous one  ensure the sustainability 
	of the programming language.

\subsection{A Focus on Some Active-object Languages}


\subsubsection{Rebeca}
\paragraph{General presentation and objective of the language} 
Rebeca (\emph{\underline{Re}active O\underline{b}j\underline{ec}ts L\underline{a}nguage}) is an actor-based modeling language designed in 2001 \cite{DBLP:conf/csicc/SirjaniMM01,DBLP:journals/fuin/SirjaniMSB04}, as an imperative interpretation of Agha's actor model,  provided with formal semantics and supported by model checking tools~\cite{DBLP:journals/jucs/SirjaniBM05,DBLP:conf/birthday/SirjaniJ11}. Rebeca is designed for modeling and verification of concurrent and distributed systems with the goal to bridge the gap between software engineers and formal methods community, by being a usable and at the same time analyzable modeling language. 

As usability has been a primary goal in designing Rebeca, the syntax is shifted to be 
Java-like,  the computation and communication model of the core language is kept simple, 
and the analysis support is the model checking. Rebeca is an actor-based language without 
shared variable between actors and with asynchronous message passing (there is no 
blocking send or receive statement).
Because of the simple structure of the language, learning Rebeca is easy. Furthermore, using model checking tools needs far less expertise comparing to deduction-based analysis techniques.
%
Semantics of Rebeca helps analyzability,  Rebeca actors are isolated and hence various abstractions, and modular and compositional verification become less problematic to apply. Any tight coupling between the building modules of a model, like shared variables, wait statements, and synchronous message calls, can make the analysis more difficult.

Rebeca offers  perfect modeling capabilities and efficient model checking tools for 
concurrent distributed,  event-based applications with pure asynchronous message passing. 
Even so, sometimes synchronization among components, or different communication models  
are vital and the modeling of some applications becomes cumbersome. Following the 
strategy of ``pay for what you need'', while core Rebeca is kept simple,   the language 
is extended in different dimensions, creating the Rebeca family, to support modeling and 
analysis of a wider variety  of application domains. 
Extended Rebeca \cite{DBLP:conf/acsd/SirjaniBMS05,DBLP:journals/jucs/SirjaniBM05}, RebecaSys \cite{DBLP:journals/tecs/RazaviBSKSS10}, Variable Rebeca \cite{DBLP:journals/jucs/SabouriK13}, 
Broadcasting Rebeca \cite{DBLP:conf/fsen/YousefiGK15},  and Wireless Rebeca are examples 
of these extensions for modeling and analysis of globally asynchronous-locally 
synchronous systems,  hardware/software co-design (or system-level design), product-line 
of actors,  message broadcasting abilities, and mobile ad-hoc actors, respectively. 
  %Timed Rebeca \cite{DBLP:journals/scp/ReynissonSACJIS14}, and Probabilistic Timed Rebeca \cite{DBLP:journals/eceasst/JafariKSH14} real-time actors, and real-time actors with probabilistic behaviors
  In these extensions, the core Java-like syntax of Rebeca is preserved and only a 
  minimal  set of statements and keywords are added to support the requirements of each 
  application domain. 
  %This way, modelers learn one modeling language; although, they are able to use different extensions of Rebeca to analyze different kinds of systems or different aspects of a system. 
  %Rebeca also tailored for the domain of hardware-software co-design in \cite{DBLP:journals/tecs/RazaviBSKSS10} to be used as the back-end model checker of SystemC designs.
  %
Timed Rebeca 
\cite{DBLP:journals/corr/abs-1108-0228,DBLP:journals/scp/ReynissonSACJIS14} 
 extends Rebeca to capture real-time behavior and is  supported by customized efficient 
 analysis tools. Finally probabilistic behavior are supported by Probabilistic Timed 
 Rebeca \cite{DBLP:journals/eceasst/JafariKSH14} that can be analyzed using back-end 
 tools.


\paragraph{Language description} 
We describe Rebeca using an example of a Media Service system, depicted in Fig.~\ref{fig:rebeca-example}. In this example, there are some clients 
%which want to watch movies. They 
that send requests for watching movies to a dispatcher and the dispatcher 
non-deterministically redirects the request to media servers. A media server starts 
streaming upon receiving a request from the dispatcher. The Rebeca model of Media Service 
consists of a number of \emph{reactive classes}, which are \texttt{MediaServer}, 
\texttt{Dispatcher}, and \texttt{Client}, each describing the type of a certain number of 
\emph{actors} (also called \emph{rebecs} in Rebeca). A reactive class declares a set of 
\emph{state variables} (line 2). The local state of each actor is defined by the values 
of its state variables and the contents of its message queue. Following the actor model, 
communication is realised by asynchronous message passing. Each actor has a set of 
\emph{knownrebecs} of known actors to which it can send messages. For 
example, an actor of type \texttt{Dispatcher} knows three actors of type 
\texttt{MediaServer} (line 8), to which it can send \texttt{requestForMovie} message 
(lines 12-14). Each reactive class of a Rebeca model may have a constructor. Constructors 
have the same name as the declaring reactive class and does not have return value (lines 
3 and 21). Their  task is initializing the actor's state variables (line 3) and putting 
initially needed messages in the queue of that actor (line 21). %A properly written 
%constructor leaves the resulting actor in a valid state. -> LUDEO REMOVED: in which 
%language this is not true?

Message servers are defined in reactive classes in a similar way that methods are written in Java.
%Reactive classes declare the messages to which they can respond to, using Java-like syntax of defining methods. 
In contrast to the Java methods, \emph{message servers} of Rebeca does not have return value and their declarations start with keyword \texttt{msgsrv}. 
%
A message server is executed upon receiving the  corresponding message,  
and may include assignment statements,  conditional statements (lines 11 to 15), and  
message sending (lines 4 and 22).
Loops and periodic behavior is modeled by sending messages to itself (line 23). Since the communication is asynchronous, each actor has a \emph{message queue} from which it takes the next message to serve. The ordering of the messages in the message queues is first-in first-out.
%based on the arrival times of messages. 
An actor takes the first message from its message queue, executes its corresponding message server in  a non-preemptive way, and then takes the next message. The actor stays idle only if there is no other message in the queue.
%, and continues in.(or waits for the next message to arrive) and so on. 
A message server may include a \emph{nondeterministic assignment} statement which is used to model the nondeterminism in the behavior of a message server (line 10).

Finally, the \texttt{main} block instantiates the 
actors of the model. In the Media Service model, seven actors are created, receiving 
their known rebecs and the parameters' values of their constructors (lines 27-29).


\lstdefinelanguage{rebeca}{
  morekeywords={reactiveclass, knownrebecs, statevars, main, msgsrv, main, define, LTL, CTL, boolean, int, shortint, byte, if, else, while, for, wait, msg, reset, set, self, false, true, now, after, delay, deadline, initial},
  otherkeywords={=>,<-,<\%,<:,>:,\#,@},
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[n]{/*}{*/},
  morestring=[b]",
  morestring=[b]',
  morestring=[b]"""
}

\lstset{frame=tb,
  language=rebeca,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  keywordstyle=\color{blue},
  numbers=left,
  numberstyle=\color{black},
  numbersep=5pt,
  xleftmargin=5pt,
  stepnumber=1,
  frame=none,
  breaklines=true,
  breakatwhitespace=true,
  tabsize=2,
}

\begin{figure}
\begin{lstlisting}[language=rebeca]
reactiveclass MediaServer (5) {
	statevars {	byte maximumClient; }
	MediaServer(byte maxC) { maximumClient maxC; }
	msgsrv requestForMovie(Client client) { client.receiveMovie(); }
}

reactiveclass Dispatcher (5) {
	knownrebecs { MediaServer m1, m2, m3; }
	msgsrv requestForMovie(Client client) {
		byte selectedServer = ?(1, 2, 3);
		switch (selectedServer) {
			case 1: m1.requestForMovie(client); break;
			case 2: m2.requestForMovie(client); break;
			case 3: m3.requestForMovie(client); break;
		}
	}
}

reactiveclass Client(2) {
	knownrebecs { Dispatcher dispatcher; }
	Client() { self.watchMovie(); }
	msgsrv watchMovie() { dispatcher.requestForMovie(self); }
	msgsrv receiveMovie() { self.watchMovie(); }
}

main {
	MediaServer server1():(2), server2():(3), server3():(2);
	Dispatcher dispatcher(server1, server2, server3):();
	Client client1(dispatcher):(), client2(dispatcher):(), client3(dispatcher):();
}
\end{lstlisting}  
\caption{A simple Rebeca model}
\label{fig:rebeca-example}
\end{figure}

\paragraph{Degree of synchronisation} 
Conforming the Agha's actor model, the only communication mechanism among actors of 
Rebeca is asynchronous message passing. So, there is no synchronization among actors of 
Rebeca. 
% Ludo: removed : I am not sure this is really related to synchronisation
%The only condition that you may consider as a deadlock, is when all the message queues 
%of all actors are empty. 
% In this case, all the actors will stay idle and having progress is impossible. The 
%analysis tool sets of  Rebeca family support automatic deadlock-freedom check for the 
%models.  
In Rebeca, arrival of a message to its receiver message queue is guaranteed and the order 
of the messages sent by one actor to the same actor is preserved creating some form of 
guaranteed order of execution.

%Marjan
% rebeca extensions
In  Extended Rebeca \cite{DBLP:conf/acsd/SirjaniBMS05,DBLP:journals/jucs/SirjaniBM05}, Rebeca is enriched with a concept of component as a collection of rebecs that are more tightly coupled, rebecs inside a component can be synchronized by a handshaking communication mechanism. 
%At the highest level of abstraction, components only interact asynchronously via broadcasting anonymous messages. At a lower level of abstraction (within a component), computations, on the one hand are driven by asynchronous messages, and on the other hand can be synchronized by a handshaking communication mechanism. 

%RebecaSys
\LUDO{I do not really understand this paragraph and hoew this is related to 
synchronisation -- after skype: explain better vraiable protection, then the rest should 
follow}
In RebecaSys, the syntax is extended with \textit{wait} statements, and a block of 
\textit{global variables} at the beginning of the model.  RebecaSys is defined as a 
back-end language,  SystemC codes are automatically mapped to RebecaSys and then are 
formally verified. As a RebecaSys model is only created from a SystemC model 
automatically, a controlled way of using global variables  is enforced, so, racing is 
avoided. Hardware/Software co-design languages support a cycle-based synchronization 
among all parallel processes. For example, if more than one module or process can write 
in a SystemC variable then two global variables in RebecaSys are defined, for pre- and 
post- values for each cycle.  
A wait statement is also added, where a rebec waits until a Boolean expression becomes true. 
%This way we could keep the same model checking tools and techniques (including reduction techniques)
% ... multiple writer will be two variable, for pre-post, 
%Wait until a boolean expression becomes true.
%
%Variable Rebeca: 


In Broadcasting Rebeca,
broadcast statement is added to Rebeca, but there is no known rebecs, so direct message 
sending to an actor is impossible.
% there is no shared variable or synchronization
 Wireless Rebeca is an extension of Broadcasting Rebeca where in addition to broadcast to all, there are possibilities of multicast to neighbors and unicast to sender.
Neighbours of an actor are actors which sent messages to it. Here, unlike in Rebeca, we have possibility of a message getting lost, as a neighbor may move out of the reach of an actor.
\LUDO{what is your message here concerning synchronisation? -- after skype: have to say 
that this is asynchronous communication again but no point-to-point???} 

In most actor language, the status of the queue cannot be precisely introspected; this 
limits expressiveness but prevents the creation of highly unpredictable behaviors. In 
practice several actor languages allows filtering and pattern matching on the service of 
message that seems to be a reasonable compromise. \LUDO{I added this intro as it is kind 
of related with the first version of ASP that related determinacy with message filtering 
... but perhaps it is a little too complicated}
For example in Rebeca, the modeler cannot peek into the  message queues and have 
information about a message without taking the message. 
In modeling various applications, it is observed that sometimes a pattern-matching 
mechanism for choosing a message to take from the queue, like what is provided by 
Erlang,  could be very handy.


\paragraph{Degree of transparency}
In Rebeca, programmers are not exposed to the mechanism of asynchronous communication among actors. 
The  syntax  is the same as the syntax for sequential programming. 
%of Java, as a sequential programming language. 
There is no way to access the contents of message queues, and acknowledgments are not sent upon starting or finishing the execution of a message server. In addition, programmers does not have any control on the interleaved execution of actors; i.e., the internal thread of an actor takes a message from the actor's message queue and serve it in an isolated environment, regardless of the states of other actors.
%


This transparency holds for all the extensions of Rebeca.
In Timed Rebeca and Probabilistic Timed Rebeca, the message queue is changed into a message bag with time-stamped messages, nevertheless, the transparency is not changed.

%\LUDO{I would remove this paragraph, at least from here and perhaps globally: I feel 
%like 
%it is not related to the main subject ... I think}
%Variable Rebeca is defined for designing product line software, and allows all the 
%constructs of a model (i.e. reactive classes, state variables, message servers, 
%statements, ...) to be annotated. This way the modeler can show which constructs are 
%associated to each  product, and hence different concrete models are built based on the 
%annotated model. 

\paragraph{Degree of data sharing}
%Following the actor's definition, 
There is no shared variable among actors in Rebeca. Parameters in sending messages among actors are passed by value.
%, so, the value of parameters are sent to the other actors not their references. 
This  is also valid when a reference to an actor is sent as a parameter. In this case, the sent reference is created by shallow-copy of the original reference, i.e., avoiding creation of a new actor because of message passing (e.g. Fig~\ref{fig:rebeca-example} line 9) .
%Marjan: compare with ASP?
% GALS Extended Rebeca
% RebecaSys
%None of the languages in Rebeca family allows shared variables.
In RebecaSys, a block of global variables can be defined at the beginning of the model, 
but these variables are used in a controlled way as explained above.
%\TODO{Ludo: check again when I understand better the previous section on rebecasys}

\paragraph{Formal semantics and support}
To support analyzability and develop formal verification tools, Rebeca and its extensions are all equipped with formal semantics.
%One the main goal of Rebeca family languages is formal modeling and verification of actor-based models. So, all of the extensions of Rebeca are equipped with formal semantics. 
Formal semantics of Rebeca is presented in \cite{DBLP:journals/fuin/SirjaniMSB04}, and  the model checking toolset of Rebeca is developed based on this semantics. 
%Later, it is presented in Algebra of Communicating Processes (ACP) for better support of reduction techniques \cite{DBLP:conf/acsd/HojjatSMG07}. 
An ACP (Algebra of Communicating Processes) semantics is also presented in \cite{DBLP:conf/acsd/HojjatSMG07}.
%
% Marjan: if we mention BRebeca we have to mention others too
%Semantics of broadcasting Rebeca is presented as SOS (Structural Operational Semantics) rules in \cite{DBLP:conf/fsen/YousefiGK15} to provide a solid basis for its model checking toolset. 
%
Semantics of Timed Rebeca is presented as timed automata \cite{DBLP:journals/scp/KhamespanahSSKI15}, timed transition system \cite{DBLP:conf/facs2/KhamespanahSVK15}, real-time Maude \cite{DBLP:journals/scp/Sabahi-KavianiK15}, and floating time transition system \cite{DBLP:conf/facs2/KhamespanahSVK15}.
Floating time transition system is an innovative semantics for real-time actors, that results in a significant amount of reduction in time and memory consumption while verifying timed actor models. 
%It is also presented in real-time Maude to support the analysis of dynamically creating real-time actors \cite{DBLP:journals/scp/Sabahi-KavianiK15}. 
Formal semantics of Probabilistic Timed Rebeca is presented as TMDP in \cite{DBLP:journals/eceasst/JafariKSH14}. 


\newcolumntype{L}[1]{>{\raggedright\arraybackslash}m{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}}
\begin{table}
	\tbl{Summary of dimensions of comparison for  members of Rebeca family  
	\label{tab::Rebecacomparison}}{%
		
		\scriptsize
		\begin{tabular}{|L{1.8cm}|L{1.7cm}|L{1.3cm}|L{1.9cm}|L{1.3cm}|L{1.6cm}|L{1.2cm}|}
			\hline
			& \textbf{Objective} & \textbf{ Synchronization} & \textbf{Transparency} & 
			\textbf{Data Sharing} & \textbf{Formal Semantics} & \textbf{Tool Support} \\
			\hline
			\textbf{Rebeca (R)} & modeling and verification of distributed concurrent 
			systems & None & (Full) message queues and  interleaving of executions  & 
			None & SOS, ACP & Afra integrated tool, various back-ends \\
			\hline
			\textbf{Extended Rebeca (ER)} &  Globally Asynchronous-Locally Synchronous 
			Systems & local synchronous messages & As in Rebeca & None & SOS & None \\
			\hline
			\textbf{RebecaSys (RS)} & Hardware / Software Co-Design & wait statement & As 
			in Rebeca + synchronization over global variables & Global variables & LTS & 
			Model Checking, Simulation \\
			\hline
			\textbf{Variable Rebeca (VR)} & Product-lines of actors & None & As in Rebeca 
			+ feature inclusion for selected product & None & SOS & Needs help of an 
			expert\\
			\hline
			\textbf{Broadcasting Rebeca (BR)} & Actors with broadcasting abilities & None 
			& As in Rebeca + broadcasting to all actors mechanism & None & SOS & Model 
			Checking \\
			\hline
			\textbf{Wireless Rebeca (WR)} & Ad-hoc mobile networks & None & As in BRebeca 
			+ handling the connectivity of nodes + multi-casting & None & SOS & Model 
			Checking \\
			\hline
			\textbf{Timed Rebeca (TR)} & Realtime actors & delay statement & As in Rebeca 
			+ Progress of time  & None & SOS, RT Maude, Timed Automata, FTTS & Afra 
			integrated tool, various back-ends \\
			\hline
			\textbf{Probabilistic Timed Rebeca (PTR)} & Probabilistic readtime actors & 
			As in TRebeca & As in TRebeca & None & SOS & Back-ends (IMCA \& Prism) \\
			\hline
		\end{tabular}
	}
\end{table}

\paragraph{Implementation and tooling support}
There is a wide range of analysis and mapping toolsets for Rebeca family models which are 
accessible from the Rebeca home page, see \url{http://rebeca-lang.org}. The majority of 
these toolsets and libraries are integrated in Afra, the modeling and model checking IDE 
of Rebeca family models. 
Rebeca has been taught in different courses at different universities, including 
Reykjavik University, Sharif University, University of Tehran, and University of Illinois 
at Urbana-Campaign. Afra is an \textsc{Eclipse} plug-in that is used by students of these 
classes, and provides the following facilities: \LUDO{do we really want to all list the 
universities where each language is taught???}
%, Afra is an integrated tool which has been used in teaching classes different universities (Tehran, sharif, RU, UIUC)visualize and step through the counter example - queue overflow - . 
\begin{itemize}
\item Eclipse-based editor with syntax highlighting for writing the models and  properties
\item Compiler and build system integrated with error location mechanism of Eclipse
\item Model checking tool for  LTL and CTL model checking of Rebeca,
and  Floating Time Transition System generator and analyzer for Timed Rebeca
\item State space generators compatible with CADP and $\mu$CRL analysis and 
visualization toolsets
\item Facilities for traversing counter examples in case of property violation
\end{itemize}

Additionally, there are other stand-alone tool-sets for the analysis of Rebeca  
models:
\begin{itemize}
\item Simulator backend tool for Rebeca and Timed Rebeca models, generating  Erlang 
codes   \cite{DBLP:journals/scp/ReynissonSACJIS14}

\item Analysis backend tool for Timed Rebeca, generating Real-time Maude models \cite{DBLP:journals/scp/Sabahi-KavianiK15}

\item Model checking tool chain for  analysis of Probabilistic Timed Rebeca \cite{DBLP:journals/eceasst/JafariKSH14} using backend tools PRISM and IMCA

\item SysFier: model checking tool for SystemC designs  \cite{DBLP:journals/tecs/RazaviBSKSS10}

\item Sarir:  $\mu$CRL2 backend model checking tool for Rebeca \cite{DBLP:conf/acsd/HojjatSMG07}

\item Distributed model checking tool for Rebeca models \cite{DBLP:journals/eceasst/KhamespanahSMSR15}

\item Model checking tool for Broadcasting Rebeca \cite{DBLP:conf/fsen/YousefiGK15}

\item Bounded Rational LTL model checker of Rebeca  \cite{DBLP:conf/fsen/BehjatiSA09}

\item Guided search engine for deadlock detection in Rebeca models \cite{DBLP:conf/facs2/SigurdarsonSBR12}

\end{itemize}


For the summary of the mentioned aspects and comparing the features the members of Rebeca 
family refer to Table~\ref{tab::Rebecacomparison}.
\subsubsection{ABS}

\lstset{ morekeywords={module,export,import, from, interface, class,
    implements, await, get, new, local,release, suspend} }

\paragraph{General presentation and objective of the language} ABS (\emph{A}bstract
\emph{B}ehavioral \emph{S}pecification) \cite{JHSSS10} \VLAD{TODO: The first time ABS is mentioned I think it should be first the full title followed by acronym in paranthesis} is an
object-oriented, concurrent modeling language developed since 2009 in
a series of EC-funded research
projects.\footnote{\url{www.hats-project.eu},
  \url{www.envisage-project.eu}} Its ancestors include \textsc{Creol}
\cite{Elinar2006} and \textsc{JCoBox} \cite{SchaeferP10b}. 
\KIKO{General comment: the other parts of the paper are not using textsc when
naming languages. We should be consistent with this.}

In contrast to design-oriented or architectural languages, ABS code is
fully executable. There is a simulator as well as several code
generation backends (at the moment, for Java, Haskell, and Erlang). At
the same time, ABS abstracts away from features that make automatic
analysis difficult in mainstream programming languages. For example,
ABS has an object model, but it does not support code inheritance and
it enforces programming to interfaces as well as strong
encapsulation. It retains, however, modeling features that are
essential in realistic applications, for example, aliasing and
unbounded object creation.

The main design goal of ABS was to create a language that permits to
specify complex behavior of concurrent objects in a concise, natural
manner, while keeping automated analysis of that behavior feasible and
scalable. 

There are extensions of ABS to model product variability
\cite{HHJLSSW12} as well as time and other resources
\cite{johnsen15jlamp}, but these are considered to be out of scope of
the present article.

\begin{figure}
  \centering
\begin{tikzpicture}[scale=1]\small
\node[rectangle, 
          ,shading=axis,shading angle=180,top color=white,bottom color=black!25, line width=2pt,
          minimum width=9cm, minimum height=.6cm, draw] (ass) at (0,4.5) 
          {History-Based Behavioral Interface Specification};

\node[rectangle, 
          ,shading=axis,shading angle=180,top color=white,bottom color=brown!20, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (mod)
          at (0,3.9) {Syntactic Modules}; 

\node[rectangle, 
          ,shading=axis,shading angle=180,top color=white,bottom color=blue!40, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (async)
          at (0,3.3) {Asynchronous Actor-Based Communication}; 

\node[rectangle, 
          shading=axis,shading angle=180,top color=white,bottom color=blue!20, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (cog)
          at (0,2.7) {Concurrent Object Groups (COGs)}; 

\node[rectangle,
          shading=axis,shading angle=180,top color=white,bottom color=green!40, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (imp) at
          (0,2.1){Imperative Language};

\node[rectangle,
          shading=axis,shading angle=180,top color=white,bottom color=green!20, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (object) at
          (0,1.5){Object Model};
\node[rectangle, 
          shading=axis,shading angle=180,top color=white,bottom color=yellow!60, line width=2pt,
          minimum width=9cm, 
          minimum height=.6cm, draw] (exp) at (0,0.9) {Pure
            Functional Programs};

\node[rectangle
          ,shading=axis,shading angle=180,top color=white,bottom color=yellow!40, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (adt) at
          (0,0.3){Algebraic (Parametric) Data Types};
\end{tikzpicture}
\caption{Syntax layers of the ABS language}
\label{fig:layer}
\end{figure}

\paragraph{Language description} 
In Fig.~\ref{fig:layer} the language layers of ABS are
displayed. Based on parametric (first-order) abstract data types, a
simple, pure, first-order functional language with pattern matching
and strict evaluation is defined. On top of that are objects and a
standard imperative layer. So far, this is very much like
\textsc{Scala}-light.

The central issue for achieving automated, scalable analysis is the
design of the concurrency model. Formal analysis of multi-threaded
languages with interleaving semantics, for example, \textsc{Java} \KIKO{Why uppercase?},
while principally possible \cite{BlomHuisman14}, is highly complex and
seems to be out of scope at the moment for relaxed memory consistency
models. To achieve feasibility, the concurrency model of ABS carefully
restricts the possible interactions among concurrent tasks while still
allowing to describe complex, realistic behavior of asynchronous
systems. \KIKO{Tasks are mentioned but have not been defined 
At this point, the reader may understand tasks as C\# tasks. This is explained with
the example afterwards. I believe it may make sense to explain this and the COG
concept before.} 
%
More precisely, the ABS concurrency model is based on cooperative
scheduling. This means that no task is preempted (interrupted) unless
its modeler explicitly allows to do that. There are two expressions in
ABS that explicitly release control: \lstinline{release} and
\lstinline{await}. The former is unconditional while the latter has a
Boolean argument and can be used to synchronize with another task. \VLAD{I think it is important here to mention that task results are captured in futures and used for synchronization to better understand synchronization between tasks}

\begin{figure}
  \centering
\begin{lstlisting}[numbers=left,xleftmargin=4ex,escapechar=\%]
module Services;
import Data, init, modify from CustomerData;

interface Server {
  Unit process(Fut<Data> fd);
}

class Service implements Server {
  Unit process(Fut<Data> fd) {
    await fd?; %\label{abs:process:awaitd}%
    Data rd = fd.get;
    rd.modify(); %\label{abs:process:sync}%
  }
}
{ // main block
Server s = new local Service(); %\label{abs:main:begin}%
Data d = new local Data(); 
Fut<Data> fd = d!init(); %\label{abs:main:init}%
s!process(fd); %\label{abs:main:end}%
}
\end{lstlisting}  
  \caption{A simple ABS model}
  \label{fig:abs-simple}
\end{figure}

%% Besser producer/consumer?

% module Services;

% interface Server {
%   Unit produce();
%   Unit consume();
% }

% class Service implements Server {
%   Int MAX = 17;
%   Int stock = 0;
  
%   Unit produce() {
%     while (True) {
% 	  await stock < MAX;
%       stock = stock + 1;
%       }
%   }
  
%   Unit consume() {
%     while (True) {
%       await stock > 0;
%       stock = stock - 1;
%       }
%   }
% }

% { // main block
%   Service s = new Server();
%   s!produce();
%   s!consume();
% }

We explain the concurrency model of ABS with help of the code in
Fig.~\ref{fig:abs-simple}. The unit of distribution in ABS is a
\emph{concurrent object group} (COG) which can be thought of as a set
of tasks that share a common heap and a single processor. Each task
executes code owned by an object and at most one task is active in a
given COG at any time. New tasks are created by asynchronous method
calls as well as, initially, by selecting the main block of a
module. An example of the latter is the code in
lines~\ref{abs:main:begin}--\ref{abs:main:end}.

Line~\ref{abs:main:begin} declares and creates a new object with
interface type \lstinline{Server} using the implementation in class
\lstinline{Service}.  The directive \lstinline{local} places the
object in the current COG. Without \lstinline{local} a new COG is
created together with the object. The next line declares and creates a
data object (note that interface \lstinline{Data} must be imported) in
the same COG. Hence, \lstinline{s} and \lstinline{d} share the same
heap. Line~\ref{abs:main:init} calls an initialization method
(implementation not shown) on the data. The notation ``\lstinline{!}''
signifies an asynchronous call. Its effect is to create a new task in
the COG of \lstinline{d} that executes the code of
\lstinline{init()} \VLAD{TODO: emphasize the programming to interfaces paradigm by means of not having the implementation of init}. Asynchronous calls do not interrupt the caller, so
the statement following the call is immediately executed. Therefore,
we need a handle by which to retrieve the result of an asynchronous
call once its result has been computed. In ABS the type of such
handles have a future annotation. As can be seen in
Line~\ref{abs:main:end}, it is possible to pass futures as
parameters. This makes it possible to use the result of an
asynchronous call in different places without copying it.

After execution of the main block finished, two tasks in the current
COG are waiting, corresponding to the calls to \lstinline{init()} and
\lstinline{process()}, respectively. None of them could have started
while the main block was still executing, because there was no
synchronization expression in the latter. ABS does not determine which
of \lstinline{init()} and \lstinline{process()} is started first. In
fact, ABS can be parameterized with different scheduling
strategies \VLAD{TODO: "but each object has a FIFO ordering of the tasks"}. The static analyzers of ABS take all possible scheduling
sequences into account.

A first synchronisation point is reached in
Line~\ref{abs:process:awaitd} of \lstinline{process()}. It ensures
that the value of the future \lstinline{fd} is available. If
\lstinline{init()} had not been scheduled before, it will be now. Once
the value of \lstinline{fd} is available, it is retrieved with a
\lstinline{get} expression. Note that \lstinline{rd} and \lstinline{d}
might well be aliased. The standard ABS idiom for asynchronous calls
in ABS is as follows:

\begin{center}
  \lstinline{Fut<T> fx = o!m(); ... ; await fx?; T x = fx.get;}
\end{center}

In many cases \lstinline{await} and \lstinline{get} follow an
asynchronous call directly. For this common situation the abbreviation

\begin{center}
  \lstinline{T x = await o!m();}
\end{center}

is provided which avoids the declaration of an explicit future.

Line~\ref{abs:process:sync} contains a synchronous call which is also
possible in ABS. It results in sequential behavior, i.e., yields the
processor to the callee and blocks the caller until it
returns. Obviously, here we are interested only in the side effect
that \lstinline{modify()} has. Synchronous calls are only permitted in
the COG of the caller object. \LUDO{add a sentence for release/suspend} 

\paragraph{Degree of synchronisation} 
If one attemps to retrieve a future value that is not yet ready, this
results in blockage of its COG until the value becomes
available. Obviously, this can easily lead to deadlocks. Many
deadlocks can be avoided by guarding \lstinline{get} expressions with
an \lstinline{await} (Line~\ref{abs:process:awaitd}). Clearly, not all
deadlocks can be prevented in this manner. In practice, however,
deadlocks are easy to avoid, because synchronisation points are
explicit. In addition, ABS comes with an automated deadlock analysis
tool for ABS \cite{CGM:SoSym2014} that detects all potential
deadlocks.  An important point is that between explicit
synchronisation points (\lstinline{release}, \lstinline{await}) no
data races can occur and computations are, therefore, deterministic.

\LUDO{while I agree concerning data races, the order of service of requests is also non 
deterministic, thus return also creates non-determinism somehow}

\paragraph{Degree of transparency}

ABS is an abstract language and implementation-specific aspects
including scheduling, message queueing, object representation are
hidden from the modeler. Abstract data types and interfaces can be
used to postpone detailed design decisions while still permitting
analysis of those aspects of a model that are fully specified.

\LUDO{added the following paragraph}

In ABS the user controls however the potential interleavings of the tasks and explicitly 
writes task release points using \lstinline{release} and \lstinline{await}. As a 
consequence he is exposed to the notion of asynchronous vs.synchronous calls, futures, 
and thread interleaving.

\paragraph{Degree of data sharing}
\LUDO{I do not understantd this first part. I thought all AOs were accessible from any 
COG and all other data was immutable and thus safe; can you explain better}
Between different COGs no data sharing is possible. The attempt to
call a method in a remote COG with a local class argument results in a
runtime error. Within the same COG all tasks have acess to a common
heap and can modify shared data. 
\LUDO{the rest is OK but I would mention that all objects of the COG are accessible (via 
nmethod calls) if this is indeed true}
However, objects have strictly
private visibility, that is, they can only directly access their own
fields. The fields of any other objects must be accessed by explicit
method calls (getter/setter methods).

\paragraph{Formal semantics and support}

ABS has a fully formal, small step operational semantics
\cite{hats-d1.2} that permits formal soundness theorems for the
various analyses that are available for ABS. This semantics is
directly expressed in terms of rewrite rules in \textsc{Maude} format
\cite{ClavelDELMMT07} which yields a sound interpreter for ABS.

In addition there is an axiomatic semantics in the form of a program
logic~\cite{ref:key}. The behavior of interfaces and classes can be
specified by invariants over the histories of symbolic states as contracts 
between processes. 
Because preemption is excluded in ABS it is sufficient to establish
invariants upon object creations, at explicit synchronisation points and 
upon the termination of methods.  It is possible to prove a composition 
theorem for ABS about the relation between local and global invariants
\cite{Din14fac}. This makes it possible to prove global behavioral
properties of an ABS model by (method-)local reasoning.

\paragraph{Implementation and tooling support}

As ABS has been developed with the goal of being analysable, there is
a wide range of tools available. Most of them support the full ABS
language and are fully automatic. An overview of several of the tools
is available as \cite{BFH14,WongAMPSS12}.

There is an \textsc{Eclipse} plug-in that provides a development
environment for ABS and integrates most tools, see
\url{http://tools.hats-project.eu/eclipseplugin/installation.html}. An
alternative is the web-based ABS collaboratory at
\url{http://ei.abs-models.org:8082/clients/web/} which requires no
installation and also permits to try out most ABS tools.  Here is a
list of currently supported tools for ABS:

\begin{itemize}
\item editor with syntax highlighting and integrated build system,
  including compiler error location;
\item simulator/interpreter with interactive debugger;
\item visualization of ABS model execution as sequence diagram;
\item code generator backends for Erlang, Haskell, ProActive~\cite{rochas:hal-01065072}Java
  8~\cite{serbanescuNABN14a};
\item a glass box test case generator for \emph{concurrent} models \cite{AlbertAGM15};
\item a sound deadlock analysis \cite{CGM:SoSym2014};
\item a worst-case resource analysis that can be parameterized with a
  cost model for execution time, memory consumption, transmission
  size, peak cost and various other cost categories \cite{AlbertAFGGMPR14};
\item a deductive verification tool for expressive, history-based
  property specifications \cite{ref:key}
\end{itemize}


\subsubsection{ProActive and ASP}
\paragraph{General presentation and objective of the language}
ASP~\cite{CH-book} is an active object programming language especially designed for
programming and deploying distributed systems. ProActive is a Java library implementing the semantics
of the ASP calculus. The language is designed taking the constraints of distributed
programming into account, and relies on Remote Method Invocation as the communication layer even though
other communication mechanisms can be used. ProActive is intended for distributed execution; it
is a middleware that supports application deployment on distributed infrastructures such
as clusters, grids and clouds. Several choices for the design of the language can be
explained by these practical concerns.

One of the design choices for ASP and ProActive is to ensure maximal transparency for the 
programmer: active objects and futures are manipulated like usual Java objects. The 
ProActive middleware automatically triggers asynchronous remote invocations and performs automatically blocking synchronisation when 
needed. ProActive is thus intended to Java programmers that are not particularly experts 
in concurrent and distributed programming. 

Another choice is that active objects are coarse grain entities. We create a dedicated 
thread for each of them and they come with a quite heavy machinery  for managing each 
object and communicating between objects. The machinery ensures all the distributed 
nature of the computation. As a consequence, using the ProActive library, 
it is not possible to instantiate thousands of active objects on the same core. Of course 
the number of passive objects is not particularly restricted.

Since 2010, ASP features
\emph{multi-active objects}~\cite{HHI2013:mao} meaning that in each active object, several
threads can run in parallel and process several requests of this active object, but each thread is still isolated inside a single activity. 
Such multi-active objects feature at the same time local concurrency and global 
parallelism.

\paragraph{Language description}
In ASP, active objects coexist with objects that are not active; we call them 
\emph{passive} objects. An active object together with its 
service thread(s) its passive objects, and its request queue is called an activity. 
Each passive object is placed under the responsibility of an active object.
Only active objects are accessible between activities. The 
objects that are not active are only accessible within an activity; if those 
objects need to be used by several activities, they are copied in each activity. Based on this 
clear separation, the activity is the unit of distribution, which matches the usage of one memory space per activity. 
In ASP, when using multi-active objects, 
several threads can execute in the same activity, thus several threads can potentially access the objects of an activity. 

The language is transparent: method calls are automatically turned into asynchronous 
requests if the targeted object is a remote active object, otherwise it is a synchronous, local method call. Similarly, futures are 
implicitly created upon asynchronous calls. Futures are also transparently manipulated: 
a wait-by-necessity is automatically triggered upon an access to an unresolved future. 
In ASP, futures are first-class: they can be passed between activities. In this case, 
when the future is resolved, the result is automatically updated at all locations.

ProActive offers an API to create active objects, 
and a runtime for handling ASP features. The following is an example of ProActive program:
\lstset{
	emph={parameters,node}, 
	emphstyle=\itshape
} 
\begin{lstlisting}
O o = PAActiveObject.newActive(O.class, parameters, node);
T t = PAActiveObject.newActive(T.class, parameters, node);
V v = t.bar(); 	// implicit asynchronous method call
o.foo(v); 	// v can be passed without blocking
v.foobar(); 	// potential wait-by-necessity on v
\end{lstlisting}
%%% THE FOLLOWING MIGHT BE TOO DETAILLED %%%
 An active object is created using \code{newActive}, instead of the \code{new} of Java.
 The \code{newActive} primitive takes as parameters the class to instantiate, the parameters of the
 constructor, and the node on which the active object will be deployed.
 The variable \code{v} is the result of an asynchronous call; it is an
 implicit future.
% The dynamic type of \code{v} is a future that is a dynamically created subtype of 
%\code{V}. 
 When the future value is needed to continue execution, such as in \code{v.foobar()}, 
 a wait-by necessity automatically occurs if the future is not resolved. In ProActive,  
 proxies are used to handle transparently active objects and futures.
% In ProActive, when an active object is created, it is registered in the
% RMI registry delivered with Java. A local reference to this active object is also created: 
% a proxy that delegates invocations to the active object.

 The principle of the multi-active object programming model is to execute multiple
 requests of an active object in parallel, while controlling the concurrency. 
 In practice, the 
 programmer can declare which requests (i.e. which methods of the active object) can be 
 safely executed in parallel. Such requests are 
  called \emph{compatible} requests. The internal scheduler of an active object will allocate by default
 as many threads as necessary to run compatible requests in parallel.
  In 
 ProActive, multi-active object features
  can be used through a metalanguage, based on Java annotations. The 
 following is an
 example of multiactive object annotations in ProActive: 
 \lstset{morekeywords={@DefineGroups,@Compatible,@DefineRules,@Group,@MemberOf} }
\begin{lstlisting}
@Group(name="group1", selfCompatible=true)
@Group(name="group2", selfCompatible=false)
@Compatible({"group1", "group2"})
public class MyClass {
  ...
  @MemberOf("group1")   
  public ... method1(...) { ... }
  
  @MemberOf("group2")   
  public ... method2(...) { ... }
}
\end{lstlisting}
In this example, two groups of requests are defined, each of them holding one method. 
The two groups are declared to be compatible (so as their method, by extension). The 
\code{selfCompatible} parameter defines whether two different requests of the same group 
are allowed to run in parallel. At runtime, a ready request is automatically executed if 
it is compatible (i) with requests that are already executing and (ii) with older 
requests in the queue. The first condition (i) prevents data races. The second condition (ii) preserves the ordering of non-compatible 
requests. The second condition (ii) also prevents starvation that would arise if many requests of a group 
$G$, 
that are only compatible with executing requests keep overtaking requests of another 
group $G'$, with which they would not be compatible. 

Without annotations, a multi-active object is a mono-threaded active object,
without
any local parallelism nor any possible race condition. Programming a mono-threaded active object-based application with ProActive is thus extremely simple. If some
parallelism is desired, a compatibility should be declared between requests
that can be safely interleaved and for which execution order do not matter.
To define a compatibility between two requests, the programmer can also use runtime information such as the request parameters or the object's 
state. Programming a multi-active object-based application with ProActive is thus a bit more difficult than programming mono-threaded ProActive active objects, but it is less complicated than programming with raw threads and low-level synchronization mechanisms while giving a competing parallelism compared to those ancient techniques.
However, if even more parallelism, out of the scope of request compatibility, is required, the programmer can still define more requests as compatible, and prevent unexpected behaviours with traditional low-level Java synchronisation 
primitives, this mixed approach goes beyond the traditional 
active-object model.

Other high-level specifications are available in multiactive
objects~\cite{henrio:hal-00916293}, such as request priority. To avoid thread explosion,
it is also possible to set a limit on the number of threads running in parallel.  The
limit can be applied in two ways: a hard limit restrains the overall number of threads
whereas a soft limit only counts threads that are not in wait-by-necessity. 
Additionally, threads can be limited per group.

As a conclusion, ASP and ProActive are based on the multiactive object programming
model.
This model is well adapted to non-expert because it provides high-level features for distribution 
and safe concurrency.

\paragraph{Degree of synchronisation}
In ASP, the only blocking synchronisation is the wait-by-necessity on a future. In this case, as requests run until completion, potential deadlocks can arise in 
case of reentrant calls, especially if no compatibility annotation is specified. 
However, synchronisation only occur when the future value is actually needed and, in 
particular, future references can safely be transmitted between activities without 
requiring any additional synchronisation, which limits blocking synchronisation leading 
to deadlocks.
Deadlocks can also be removed by using multi-active objects especially with no limit or a 
soft limit of the number of threads. In particular,
when a thread becomes in wait-by-necessity, it is not counted in the soft thread limit of 
the active object any more, so the wait-by-necessity event potentially causes the start 
of another request.

\paragraph{Degree of transparency}
In ASP the programmer is not explicitly exposed at all to the notion of future and in a moderate way to the notion of active object (at active object creation time only). The syntax is the same as the syntax for sequential 
programming, there is no specific construct for waiting a future value or performing an 
asynchronous call. Very often a sequential code can be reused unchanged in a distributed 
setting.

When dealing with multiactive objects, the programmer is exposed to the notion of 
parallel treatment of requests, the programming model becomes more explicit concerning 
concurrency aspects. 

\paragraph{Degree of data sharing}
ASP follows a strict policy of absence of sharing between active objects. Objects that are 
not active objects and are passed by copy between activities (as request parameters or request 
results). Of course this mechanism applies also to objects that referenced by passed 
objects; a deep-copy mechanism is used ensuring that, when objects are transmitted 
between activities, they are copied as well as all their dependency on the destination 
side. This mechanism, which is the one used by RMI, slows down request invocation in practice because 
of the time spent to transmit data, but accelerates request treatment because there is no 
need to contact another activity to get the value of the request parameters. Note that 
active object and future references are passed by reference.

There is no coherency ensured between the different copies of a passive object, thus if 
the user wants to ensure that an object has a unique coherent state, he should not 
transmit it by copy, and in this case transmitting an active-object reference instead would be the best choice.

\paragraph{Formal semantics and support}

Several papers formalise the semantics of ASP. The first of them formalised the 
mono-threaded part of the language and proved some determinacy 
properties~\cite{CHS:POPL04}. In particular, this paper proved that the order of future 
updates has no influence on the execution and that the only source of non-determinacy in 
mono-threaded ASP is when two activities can send a request to the same destination.
A functional fragment of the calculus has also been 
formalised in Isabelle/HOL~\cite{HKL:SCP11}. A specific semantics has been exhibited in 
order to evaluate a functional ASP program without risk of having a deadlock; the absence 
of deadlock has been proved in Isabelle/HOL.
The full semantics of imperative ASP with multi-threaded activities is published 
in~\cite{HHI2013:mao}.


\paragraph{Implementation and tooling support}
ProActive is the Java library implementing ASP semantics. 
In ProActive, in order to transparently handle active objects and futures, a proxy is created for each of them. Proxies encapsulate all needed code to perform asynchronous, remote method invocations and wait-by-necessity behaviour. Whenever an active object or a future is given as parameter of a call to an active object,  it is in fact their proxy that is copied. This way, all copies of a proxy of an active object/future points to this same active object/future. 
Another particular aspect of ProActive deals with
the deployment of ASP active objects on distributed infrastructures. The design choices of the programming language typically target a high performance of distributed ProActive applications. 
In order to settle active objects on distributed infrastructures, ProActive features a deployment specification mechanism. The goal of this mechanism is to make the physical deployment independent from the the deployment logic. This is possible by having a binding from virtual node names, used in the source code, pointing to machine addresses or names. In practice, this binding is implemented in XML configuration files. Also, since the binding is made at \emph{deployment time}, changing infrastructure for a given ProActive application is only localised in a few files and does not require application recompilation. 
Several machines can be aggregated under a single virtual node name in the deployment logic, for example to provide the virtual node with some properties or non functional deployment options (such as fault tolerance or logging).


As shown in~\cite{BHR2014:gcm}, ProActive active objects, and active objects in general,
provide a convenient programming model for component based composition of distributed
applications. The ProActive library implements the GCM distributed component model. In
this context, the Vercors
platform~\cite{HKM-FASE16} provides
verification capacities for ProActive components; Vercors consists of an Eclipse plugin
for designing component systems; from this point the Vercors platform can on one hand
verify the correct behaviour of the application using the CADP model-checker, and on the
other hand generate an executable ProActive/GCM code corresponding to the designed system.

\lstdefinestyle{encore}{
  language=java,
  basicstyle=\tt\color{black},
  keywordstyle=\tt\bfseries\color{blue},
  commentstyle=\it,
  aboveskip=1ex,
  belowskip=1ex,
  tabsize=2,
  columns=fullflexible,
  xleftmargin=1ex,
  resetmargins=true,
  showstringspaces=false,
  morecomment=[l]{//},
  morecomment=[s]{/*}{*/},
  escapeinside=??,
  morekeywords={assert,exclusive,stable,atomic,immutable,locked,lockfree,unsafe,trait,require,async,finish,def,consume,finish,async,J,S,var,val,shared,safe,subordinate,I,let,in,excl,then,else,wlock,wlocked,rlock,rlocked,read,thread,synchronise,linear,unpack,pack,subord,sync,bound,as,encaps,active,passive,requires,Fut,suspend,await,get}
}

\lstnewenvironment{ecode}{\lstset{style=encore}}{}
\lstnewenvironment{ecodep}[1][numbers=left]{\lstset{style=encore,#1}}{}
\newcommand{\ec}[1]{\lstinline[style=encore,basicstyle=\tt]@#1@}
\newcommand{\Upscale}{\textsc{UpScale}\xspace}

\subsubsection{Encore}\label{sec:encore}

\paragraph{General presentation} Encore \cite{ref:encore}
is a general purpose parallel language based on active objects
developed since 2014 by an
EC-funded research project.\footnote{EU project FP7-612985 \Upscale:
From Inherent Concurrency to Massive Parallelism through Type-based~Optimisations.} 
The language has been designed to excel at scalability and rests on four pillar concepts: 
\textit{parallel by default} using the
active object paradigm for coarse grain parallelism, \textit{independent
local heaps} to promote data locality, \textit{type-based synchronisation directives}
provided by a novel capability system and \textit{coordination of parallel
computations and low-level data parallelism} via parallel combinators. 
%\TW{Make sure to revisit all of these pillars properly in the text. (And that it is easy to find them.)}
On top of these key ingredients, Encore stays loyal to the object-oriented paradigm
where active objects and futures can be seen as normal Java objects and,
instead of interfaces, provides a trait system \`a la Scala.

\paragraph{Language description}
In Encore, active objects have their own thread of control and communicate with each 
other by asynchronous message sends. Messages are appended to the receiver's message queue
and processed one at a time in FIFO order.
Active objects act like ``plain old Java objects'', except that
they have an asynchronous interface.
Active objects encapsulate
passive objects, and operations on passive objects are synchronous. 
%
Each active object owns a local heap on which it can
allocate passive objects. Ownership in this context means that the
actor is responsible for keeping track on foreign dependencies on
passive objects on its local heap, and eventually deallocate them. 
Passive objects may be shared with other active objects, or transferred,
but are susceptible to data-races.
%The passive objects on a local heap may be shared with
%other active objects, or transferred, but are susceptible to data-races.

Encore is \emph{parallel by default}, active objects provide coarse-grain parallelism although,
an active object cannot work on multiple method calls at the same time;
%
Fine-grained parallel computations can be created via the notion of tasks
%to create fine-grain parallel computations Encore supports the creation of tasks.
%A task (\ec{async \{ e \}}) contains a body \verb|e| that is asynchronously executed
(\ec{async \{ e \}}), which contain a body \verb|e| that is asynchronously executed
and, whose return value is immediately a future. Tasks are more lightweight
that actors (memory-wise) and increase the level of asynchrony on the system.

Method calls on active objects and spawning of tasks immediately return a future value
that, unlike ProActive, has the explicit type \ec{Fut t}, for
some \ec{t}. Futures support future chaining,
and both \ec{get} and \ec{await} operations similar to ABS.
%
These operations are explained in detail later (in \emph{Cooperate Scheduling of Active Objects}).

The example below (Fig.~\ref{fig:encore:example}) shows a buffer implementation
using features of the Encore language.
%
\begin{figure}[t]
\begin{parcolumns}{2}
\colchunk{
\begin{lstlisting}[style=encore, firstnumber=1, lastline=14,numbers=left,xleftmargin=4ex,escapechar=\%,basicstyle=\small\tt,columns=fullflexible, showlines=true]                                                           
trait TQueue {
  requires top
  
  def enqueue(x: int): void
    this.top = new Data(x, this.top)
}

passive class Data { 
  ... 
}    

passive class Queue : TQueue {
  top: Link
}  
\end{lstlisting}
}
%
\colchunk{
\begin{lstlisting}[style=encore, firstnumber=14,numbers=left,xleftmargin=4ex,escapechar=\%,basicstyle=\small\tt,columns=fullflexible]                                                           
class Buffer
   queue: Queue
   
  def init(): void
    this.queue = new Queue()
    
  def put(item: Data): void
    this.queue.enqueue(item)

class Main
  def main(): void
    let buffer = new Buffer()
        data = new Data(21)
     in buffer ! put(data)
\end{lstlisting}
}
\colplacechunks
\end{parcolumns}
\caption{\label{fig:encore:example}Example of a Buffer implementation that uses traits, active and passive objects in Encore.}
\end{figure}
%
In this example, the \ec{Buffer} class is an active object with
a private \ec{queue} of type \ec{Queue}, which is a passive class. \ec{Queue}
implements the \ec{TQueue} trait (line 12). A trait can be
thought of as a Java interface with defined methods and may require some attributes to be present
in implementing classes. For instance, \ec{TQueue}
requires the existence of an attribute \ec{top} and provides the implementation
of the \ec{enqueue} method (lines 1 -- 6). Any passive object of type \ec{Queue} has an implementation
of methods defined in the traits it extends, in this case, the \ec{enqueue} method. The \ec{Main}
class is the entry point of the program and creates an active object (\ec{buffer}, line 25) and
some data (line 26); the method call (line 27) \ec{buffer ! put(data)} is a
uni-directional message send, i.e., it does not
return a future. If it was rewritten as \ec{buffer.put(data)}, it would return a \ec{Fut void}
value, which would allow the called to detect when the put message is finished processing on the receiver
side. 


\paragraph{Cooperative Scheduling of Active Objects}

Encore supports versions of the \ec{suspend} (\ec{suspend :: void -> void}),
\ec{get} (\ec{get :: Fut t -> t}), and \ec{await} (\ec{await :: Fut t -> void}) statements similar to ABS. 
%In contrast with ABS, Encore
%supports using suspend and await anywhere in a program, as opposed
%to ABS which only permits calling these operations inside active objects.
%\LUDO{I am still not sure what is meant here: in abs all objects are kind of  active 
%no?}.
%This is due to underlying  technical reasons
%described in the implementation sections of Encore and ABS
%\TW{Make it so! :) Encore threads yadayada.}. 
Encore's \ec{await} statement is somewhat limited in relation to ABS's as it only
supports awaiting the fulfilment of a future, and not any boolean
condition and differs from ProActive's \ec{await} (Section \ref{subsec:proactive-backend-abs}).
Encore's support for future chaining however makes
\ec{await} less useful as chaining allows triggering arbitrary operations on the fulfilment futures. 
%The type signatures of the operations
%are found below:
%
%\begin{center}
%\begin{tabular}{rcl}
%\ec{suspend} & \ec{::} & \ec{void -> void} \\
%\ec{    get} & \ec{::} & \ec{Fut t -> t} \\
%\ec{  await} & \ec{::} & \ec{Fut t -> void} 
%\end{tabular}
%\end{center}

A pictorial overview of the semantics of \ec{suspend}, \ec{await}
and \ec{get} is found in Figures~\ref{fig:enc-suspend} and
\ref{fig:enc-get-await}. It shows how the operations may involve
\emph{descheduling} an object (removed from round-robin scheduler
queue), \emph{blocking} (no processing of other messages in the
object's queue), and whether a resuming message is prepended or
appended to the object's queue.


\begin{figure}[t]
  \centering
  \includegraphics[scale=.35]{pictures/enc-basic}
\qquad
  \includegraphics[scale=.35]{pictures/enc-resume}
  \caption{(Left) An Encore scheduler, local to one core. A
    scheduler has a queue of active objects with non-empty message
    queues. (Right) The state after the execution of \ec{suspend} in the left 
    configuration.}
  \label{fig:enc-suspend}
\end{figure}

\begin{figure}[t]
  \centering
%  \includegraphics[scale=.4]{pictures/enc-get-await-fulfilled}
  \includegraphics[scale=.30]{pictures/enc-get-unfulfilled}
\qquad
  \includegraphics[scale=.30]{pictures/enc-await-unfulfilled}
  \caption{(Left) An Encore program executing a \ec{get} on an
    unfulfilled future. This causes the currently executing
    active object to be unscheduled, only to be rescheduled after
    the future has been fulfilled. Once the object gets to the
    head of the scheduling queue after this point, the \ec{get}
    operation returns and the program continues from this point.
    with non-empty message queues. (Right) An Encore program
    executing an \ec{await} on an unfulfilled future. In
    difference with \ec{get}, the active object is only
    unscheduled if it does not have any messages in its message
    queue, and once the future is fulfilled, the resuming method
    is placed at the end of the active object's queue.}
  \label{fig:enc-get-await}
\end{figure}


\paragraph{Parallelism Inside Active Objects}

\newcommand{\bind}[0]{\ensuremath{\gg\!\!=}}
\newcommand{\prune}[0]{\ensuremath{\ll}}

Active objects provide coarse grain parallelism via futures but do not offer
high-level language constructs for low-level coordination of parallel computations.
In order to express complex coordination workflows, such as pipeline and
speculative parallelism, Encore incorporates
\parT{} collections and associated parallel combinators.
A \parT{} collection is an abstraction that can contain asynchronous computations
and values and it is controlled via parallel combinators. 
\parT{} computations have type \ec{Par t} (\ec{t} is a polymorphic type).
%but it represents more than a mere container, as \parT{} can be seen as a handle to these
%asynchronous computations, exploited via the combinators.
%
%\parT{} collections have the type \texttt{Par t} (\texttt{t} is a polymorphic type)
%and can contain values and asynchronous computations
%represented by futures.

%Futures created from tasks or methods calls on active objects can be lifted
%to the \parT{} abstraction via the \emph{lift} combinator (lift :: Fut t $\to$ Par t);
%the $\|$ construct ($\| :: Par \;t \to Par \;t \to Par \;t$) merges two \parT{}s
%into a new \parT{} collection. 
%This operation does not create new threads but, exploits the inner parallelism
%within the \parT{}s, i.e., the runtime can detect when there is a potential possibility
%for spawning more tasks,
%increasing the degree of asynchrony while keeping the throughput of the system.

The \parT{} combinators are informally explained with the example from Fig.~\ref{fig:encore:factorisation},
which computes the LU and Cholesky factorisation in parallel, inverting these matrixes asynchronously,
getting the diagonal of the first asynchronous computation that finishes the inversion of the matrix
and terminating the remaining computations.
%
The LU and Cholesky factorisation are performed in parallel, spawning tasks (lines 6 and 7),
lifting and grouping the futures into a \parT{} abstraction (line 8) via the \emph{lift} (lift :: Fut t $\to$ Par t)
and $\|$ combinators ($\| :: Par \;t \to Par \;t \to Par \;t$) which lift the future to a \parT{} and
merges two \parT{}s into a new \parT{} collection, respectively.
%
The inversion of the matrix is performed asynchronously, using the \bind{} combinator
($\bind \ :: Par \ t \to (t \to Par\ t') \to Par\ t'$), line 10, which receives a function (second argument)
that is applied asynchronously to the items in the \parT{} collection --- creating pipeline parallelism. 
%
With the \prune{} combinator ($\prune \ :: (Fut \;(Maybe \;t) \to Par \;t') \to Par \;t \to Par \;t'$), line 10,
the \verb|getDiagonal| function is applied to the first computation that returns the inverted matrix,
stopping the remaining computations --- safely stops speculative work.

\begin{figure}[t]
\centering
%\begin{parcolumns}{1}
%\begin{parcolumns}[colwidths={1=2.8in,2=3.1in}, distance=0em]{2}
%\colchunk{
%\begin{lstlisting}[style=encore, firstnumber=1,numbers=left,xleftmargin=4ex,escapechar=\%,basicstyle=\small\tt,columns=fullflexible]                                                           
%def luFact(m: Mtx): [Factor]
%    ...                                                                          
%                                                                                
%def choleskyFact(m: Mtx): [Factor]
%    ...
%                                                                                
%def mtxInv(f: [Factor]) : Par [Mtx]
%    ...
%
%def getDiagonal(f: Fut<Maybe [Mtx]>)
%: Par [Factor]
%    ...
%
%\end{lstlisting}
%}
%
%\colchunk{
\begin{lstlisting}[style=encore,numbers=left,xleftmargin=4ex,escapechar=\%,basicstyle=\small\tt,columns=fullflexible]
class Main
  ...

  def main(): [Factor]
    let mtx = this.getMtx()                                            
        fLU = async luFact(mtx)
        fChlsk = async choleskyFact(mtx)
        par = (lift fLU) || (lift fChlsk)
    in
        getDiagonal <<  (par >>= mtvInv)
\end{lstlisting}
%}
%\colplacechunks
%\end{parcolumns}
\caption{\label{fig:encore:factorisation}Data-pipeline and speculative parallelism in matrix factorisation.
The types of the functions are $\mathit{getMtx :: Mxt}$, $\mathit{luFact :: Mtx \to [Factor]}$, 
$\mathit{choleskyFact :: Mtx \to [Factor]}$, 
$\mathit{mtxInv :: [Factor] \to Par [Mtx]}$ and
$\mathit{getDiagonal :: Fut<Maybe [Mtx]> \to Par [Factor]>}$.}
\end{figure}

The \parT{} collection and its combinators have been designed to perform
operations asynchronously --- without stopping the current thread of execution.
%
\parT{} integrates well in the active object model, as it
provides a uniform interface, via parallel combinators,
to manipulate a collection of asynchronous values
and can express complex coordination workflows.
%
%This creates a collection that never blocks and executes operations on demand,
%when the values are available. 
More combinators are available \cite{ref:encore}
but we have highlighted the most important ones. 
%
%\parT{} integrates well in the active object model, as it
%provides a uniform interface, via parallel combinators,
%to manipulate a collection of futures and values. Complex coordination workflows
%can be easily expressed, including but not limited
%to data-pipeline and speculative parallelism.
%Furthermore, the Encore framework can
%increase the level of asynchrony of an application, spawning more lightweight tasks,
%when it detects optimisation possibilities within the \parT{} abstraction.


\paragraph{Degree of Synchronisation}

%Like in ABS and in ASP, in Encore, synchronisation results of message passing and 
%synchronisation on futures \KIKO{ehm?}. 
In Encore, the synchronisation constructs
\ec{get} and  \ec{await} provide the same control over futures as the ABS language: 
the former blocks the active object until the future is resolved and
the latter releases the current thread of execution if the future is not resolved, so that the same
active object can continue processing other messages.
%
Furthermore, Encore provides the future chaining operator  ($\rightsquigarrow$).
 $\rightsquigarrow$ registers a callback
(anonymous function, aka lambda) to the future and continues processing the rest of
the message. The callback is executed when the future is resolved,
using the result of the future as the argument the callback.
This construct allows chaining operation on futures 
without creating synchronisation, similar to the default behaviour of 
futures in AmbientTalk~\cite{Dedecker:2006:APA:2171327.2171349},
except that it is more explicit and easier to control for the 
programmer. It is also a way to mimic transparent first-class 
futures of ASP, except that the callback request is only created when the future is 
resolved.

\paragraph{Degree of transparency}

Futures are denoted as \ec{Fut} in Encore, so non-future variables
and future variables are distinguished statically, e.g.\ \ec{int}
vs \ec{Fut int}. In other words, developers must decide which
variables are given which type, and \ec{get} could be use to
convert future type to non-future type (if the content of the
future is non-future type, i.e.\ not something like \ec{Fut Fut
  int}) by extracting the content explicitly. Both in future
management and with parallel combinators, the programmer is
exposed to the concurrent computations being handled in Encore.
However, especially when using future chaining or parallel
combinators, the scheduling and ordering of operations is handled
automatically, and the programmer only expresses concurrency from
a high-level point of view.

\paragraph{Data sharing}

In Encore, active objects are protected by their own thread of control
while passive objects are protected by a \textit{capability} type.
Encore's type system sees passive objects as resources that
are protected by a capability that governs the kind of access to it \cite{ref:encore}. 
A capability is built from a trait and a \textit{kind}. The trait provides the interface-like
feeling of OOP languages while the \textit{kind} states the ``protection'' that
the interface provides. By changing a keyword, the \textit{kind}, the interface
changes the protection level. For instance, by changing the \textit{kind} from \textit{exclusive}
to \textit{lock-free}, the interface changes the protection from an actor-like to a 
lock-free implementation. Like in RebecaSys, this creates controlled data sharing.

The Encore capabilities form the hierarchy seen in
Figure~\ref{fig:capa-tree}. Exclusive capabilities are local to
one thread only and linear capabilities may be transferred between
concurrent computations without data-races of dynamic means of
concurrency control.
%
Shared capabilities may be shared across
concurrent computations because these capabilities encapsulate
some means of protection against concurrent accesses: pessimistic
capabilities like locks and actors serialise computation;
%
optimistic capabilities like STM and lock-free capabilities allow
parallel operations but uses some form of roll-back scheme when
conflicts are detected.
%
Immutable and read-only capabilities are
always safe to access concurrently because of the absence of
writes.
%
Finally, subordinate capabilities allow constructing
aggregates of objects whose data-race freedom stems from their
proper encapsulation inside some other capability.

Encore capabilities are created from traits, and importantly,
different traits in the same class can construct different
capabilities. This allows a substructural treatment of objects,
e.g., taking a pair and splitting it into two disjoint halves,
which can be pointed to and modified separate of each other.
%
One of the more experimental features of Encore, which is far from
fully explored, is the combination of certain capabilities to
express e.g., an active object with a partially synchronous
interface (like a priority channel), or active objects which are
encapsulated inside other active objects to create constrained
active object topologies.

\begin{figure}[t]
  \centering
  \includegraphics[scale=.25]{pictures/capabilities}
  \caption{Encore capability hierarchy.}
  \label{fig:capa-tree}
\end{figure}

\paragraph{Formalization and semantics}
The Encore concurrency model has been formalized \cite{ref:encore} using
a small step operational semantics. Parallel combinators have been formalized as well,
including a soundness proof with the implicit task parallelism model \cite{encore:parallel-combinators-thesis}.
The capability type system has been formalized with proofs of soundness and data-race freedom \cite{encore:kappa}.

\paragraph{Implementation: programming and execution support}
Encore is a relatively new programming language and there is still some
limited tooling support. However, the Encore compiler can emit a
highly understandable C code.
This C code can be analysed and debug using any available tool that
works with the C11 standard. 

The currently supported tools are:

\begin{itemize}
\item Emacs and Atom editors with syntax highlighting and compiler error support
\item Support for GDB / LLDB interactive debugger
\item Vagrant support for rapid installation of Encore in a virtual machine
\end{itemize}

\section{Implementation of active objects}
In this section, we take interest in the implementations of the different active object programming models described in the previous section. In practice, the implementation of a programming language can be provided from scratch or can also be given as an API in a more mainstream language. Another way to implement an active object language is to systematically translate any of its programs into another language; this is possible through a language backend: a translator that captures the semantics of the source language. The advantage of this solution is that an active object language can then have several independent backends targeting different execution platforms and, by this means, fitting the largest needs. 

\subsection{Dimensions of Comparison between Implementations}
Several points need to be considered regarding the language runtime and how to implement 
efficiently the language semantics. We will use the points described below to compare 
active object implementations. 
%For each active object implementation, we want to address \TODO{update number of points} 
%five points, among them: how threads are created and handled to achieve the right 
%scheduling, how object are referenced throughout an active object-based application and 
%how objects and data are effectively shared. We describe them below.

\paragraph{Thread creation and scheduling}
% Virtual threads %
The active object languages that are implemented on top of an existing programming 
language (or runtime) have to comply to the constraints given by the underlying platform. 
In the case of multi-threading, some underlying platforms feature light threads
whereas in some frameworks like Java each thread is a physical one. In this case, one can 
consider implementing light 
threads on top of the underlying threads. Featuring light thread is also 
crucial if the goal of the given active object language is to scale in the number of 
active objects located on the same machine, or to cope with cooperative multithreading if 
a lot of tasks can be interrupted. 
% Continuations %
%This notion of virtual threads is particularly important when implementing an active 
%object language which features cooperative scheduling of requests: a thread  must stop 
%executing when a request is paused and must resume afterwards. 
This is a programming 
challenge when it comes to implement this behavior in programming languages that do not 
support thread serialization, like Java. 
Concerning this dimension, the following questions are raised in general: how active 
objects and requests are mapped to threads? Should the thread be a physical thread or a 
virtual one? 
%Depending on these choices, some 
%scheduling between different active objects or different requests might have to be 
%considered.

%how active objects are mapped to threads and the scheduling levels within an object and 
%BETWEEN objects

\paragraph{Data sharing and object referencing}
This point answers to the question ``Are objects shared between active objects, and 
how?'' 
Active objects encapsulate their state such that active objects are independent from each 
other.
In general, active objects prevents race-conditions by allowing a single entity (a cog 
or an active object) access to each object. This principle partitions the memory which 
limits or 
prevents data-race-conditions.
 In practice, this requires to distinguish between objects that can be remotely 
accessed (by asynchronous invocation), objects that has to be copied when exchanged 
between active objects, and objects that can be shared safely (e.g. immutable objects).
Accessing objects in another activity might involve additional communications and request 
treatment 
delays, while copying objects might lengthen the initial request invocation because of 
the serialisation time but fastens the request treatment. Handling copied objects also 
involves coherency issues. 
%Different languages take different choices on which objects are copied and how the copy 
%and the referencing of objects is handled.
%Some implementation also create a pool of immutable objects that are easier to share 
%without risk of data-race-condition. 
To communicate, objects must have a way to reference each other. 
%In particular, to send a 
%request to an active object, one must have a reference to it and be able to access it. 
%In distributed settings, an efficient active object implementation cannot rely on a 
%global shared memory, because it would be too costly. 
The ability to reference and interact with remote object raises even more questions in a 
distributed setting where a global address space is generally too costly.
How to efficiently and safely share information 
between active objects is still an on going challenge and different kinds of data sharing 
strategies have been proposed in active object implementations.


\paragraph{Error handling} %Among non-functional features an active object
% implementation can provide, we can mention
%how errors are handled.
The handling of errors is easier in a sequential program where the context of an
operation is known. Indeed, in a concurrent setting, if a task raises an error, this
will have to be reported to another task. When the second task is informed of the error
it is difficult to react properly as the conditions that raised the error are not fully
known. In the case of distributed implementations, exception handling is even more
complex as some of the exception might reveal failure of nodes or communications.
Additionally, active object implementations can offer recovery mechanisms to
allow  systems to recover after one or more active objects failed. %This support is
% particularly relevant for distributed active object implementations,
%because the failure rate is proportional to the degree of distribution.

\paragraph{Garbage collection}
%Garbage collection is another non-functional feature that an active object 
%implementation 
%should support. 
This point is important for the active object applications to scale and 
to be perennial. On most cases, the garbage collecting strategy must be implemented to 
fit a particular active object language. Even for active object languages built upon an 
underlying language with garbage collection, this language can only provide a partial 
garbage collection. Indeed, the true question in the case of active object 
implementations is when active objects are not needed any more, i.e. when they do not 
have to serve new requests.
Again, the question is even more complex in the case of distributed implementations because reference counting is scattered.

Below, we review active object implementations
%, and say whether they rely on a translation to 
%another language, or have their own runtime, or are implemented as a middleware layer, 
according to the dimensions of comparison defined above. When meaningful, we show 
experiments illustrating in which conditions the implementation outperforms existing solutions.

\subsection{Java 8 backend for ABS}\label{sec:implem-java-8}
The Abstract Behavioural Specification (ABS) language allows several programming paradigms and design patterns offering both a functional model as well as an object-oriented model. ABS has a similar syntax to Java enhanced with several new constructs and annotations that allow design of distributed applications for grid and cloud environments. Annotations can include custom defined schedulers to ease the development of batch systems and workflows. The main goal of the Java 8 backend for ABS is to translate these models into production code to be executed in a parallel or distributed environment. The challenge of this implementation is to generate the real memory structures and execution instances while being aware of the possible resource limitations, communication bottlenecks or latencies and performance, as these requirements are not easily observable at a modeling level.  
%%% Note : this is already explained before
%Active Objects in ABS are name Concurrent Object Groups (COG) and contain a set of smaller objects that run sequentially on one instance of execution.

\paragraph{Thread Creation and Scheduling}
In ABS, the core language contains constructs for the two finest levels of granularity in parallel computing which are scheduling method calls within an object and scheduling object execution within a task. Cooperative scheduling was a major challenge to implement before Java 8, as a straight implementation of ABS cooperative scheduling in Java matches a Thread to each method call and a Thread pool to each object. Therefore a construct of an asynchronous method call requires the creation of a new Thread inside a thread pool along with the start of this thread executing the method. Our research question results from the fact that each object is supposed to execute on one thread. In Java each object will be in fact a Thread pool containing the number of threads corresponding to the number of method calls invoked by the object to support that finest level of scheduling featured by ABS. This is done despite only one method running at most on that object. This underlying thread model significantly affects performance of an ABS-modelled application that is translated into Java code. This approach was used in a previous Java backend that creates a really large number of threads that occupy a large portion of the program's heap.



\paragraph{Cooperative Scheduling of Active Objects using Java 8}
\par Java 8 new features allow wrapping of method calls into lightweight lambda expressions such that they can be put into a scheduling queue of an ExecutorService to which the running objects are mapped, significantly reducing the number of idle Threads at runtime.  The only drawback is that if a method call contains a recursive stack of synchronous calls, upon preemption this stack needs to be saved, a scenario which cannot be achieved through lambda expressions. To solve this issue we focused our research in two directions:
\begin{itemize}
	\item On every preemption, we calculate the continuation and enqueue the rest of the call into the message queue.
	\item On every preemption, we try to optimally suspend the message thread until the continuation of the call is released.
\end{itemize}
The first direction is still in progress, as we have a fundamental technical limitation in the JVM/compiler. Forcing the JVM to turn the rest of a method into another method call in the object's message queue is a major challenge. The second direction however offers the following possible scenario that is illustrated in Figure \ref{abs8:coop}:
\begin{enumerate}
	\item Each asynchronous call/invocation is a message delivered in the corresponding object's queue.
	\item All objects in the same COG  compete for one Thread.
	\item A Sweeper Thread decides which task should be instantiated and be available for execution from the available queues.
	\item A thread pool executes available tasks based on a work stealing mechanism.
\end{enumerate}  

\begin{figure}
	\label{abs8:coop}
	\centering
	\includegraphics[scale=0.5]{./Sched.png}
	\caption{Cooperative Scheduling Solution}
	\label{cd}
\end{figure}


The only challenge now is when an execution of multiple synchronous calls is preempted. This results in a call stack and context that need to be saved within a thread. To do this the executing thread from the pool is suspended and will compete again, upon release, with the other available tasks in the COG for selection by the Sweeper Thread to be made available to the thread pool. However the Sweeper Thread gives priority to live threads ready for execution against new messages that have not yet become threads.

\paragraph{Data Sharing and Object Referencing}
In the Java 8 backend for ABS, objects are organized into COGs, each running on one thread. When objects are created, they are assigned a new or existing COG and all invocations on the object are executed on the same thread that belongs to the COG is it assigned. Data that is shared among distributed objects is passed through lambda expressions that are sent as serialized messages between the objects, therefore all data that passes in a distributed system needs to be serializable. When COGs reside on the same machine, for example applications that run on one multi-core machine,  all data is passed as arguments of lambda expressions or synchronous method calls in Java 8. Objects can hold as inner fields references to any other object both belonging to the same COG or a different one. Similar to data sharing, objects must be serializable to be transferred between distributed objects. Furthermore, the generated classes will be automatically loaded on all machines that require an object of a particular type, such that remote objects can invoke methods the serialized references that they receive. 

\paragraph{Active Object Scheduling Example}
To study the improvement given by Java 8 features, we benchmark a simple example that is illustrated in Figure \TODO{Figure} . In the example we have one COG \TODO{Justine: draw the COG} that contains an object which receives a large number of messages which are stored in its queue. This message recursively calls a function that creates a large stack frame after which a message is sent to a different COG \TODO{Justine: draw the COG + the message} to run in parallel a CPU intensive trigonometric function. The object is then suspended to await the result of this function, resulting in a large stack frame that needs to be saved in order to allow the next message from the queue to run on the COG.  We vary the number of recursive calls, the total number of messages in the object's queue and the complexity of the function, in order to observe a comparison with the old Java backend. The results are presented in Figure \ref{abs8:cd} The performance figures presented are for one object that is running between 10 and 10000 method invocations, each with a varying stack frame (between 1 and 1000 recursive calls) and awaits the completion of a trigonometric function that reiterates a random number (1-1000) of times before completing.  

\begin{figure}
	\label{abs8:cd}
	\centering
	\includegraphics[scale=0.6]{./pictures/absj8ex.png}
	\caption{Perfomance figures of the Two Java Backends for Cooperative Scheduling}
\end{figure}

When performing the runs for the old Java Backend, a series of 10000 messages to the same object requires the immediate creation of a corresponding number of threads, which results in the program running out of memory, thus making the HPC and Big Data applications that want to benefit from ABS cooperative scheduling feature, unusable. While the Java 8 backend clearly performs better by minimizing the number of live threads at runtime, the challenge to handle cooperative schduling of a large number of messages that are suspended and \textbf{not} released remains an open research question.


\subsection{ProActive}\label{sec:implem-proactive}
The ProActive library is all written in standard Java and provides an implementation for 
the ASP programming model. 
By default, it uses the remote method invocation Java package to implement the communication layer between active objects, although other communication protocols are possible. 
This fact drives most of the implementation singularities mentioned below.

\paragraph{Thread creation and scheduling}
In ProActive, an active object with no compatibility rule defined will be associated to one Java thread to process the requests. 
Furthermore, there is a Java thread to handle request reception in each active object. 
Java threads are mapped to operating system threads, thus ProActive uses at least two threads per active object. 
But as ProActive features multiactive objects, this number can be higher, as the active object scheduler can create Java threads on the fly to process a compatible request. 
As Java threads are pretty heavy, the ProActive scheduler implementation puts a particular effort on optimizing thread usage. 
Firstly, a thread pool is instantiated at active object start-up to ensure a basic thread reuse policy. 
Secondly, when the number of threads is limited at the application level (through multiactive object annotations), the limit literally maps to Java threads, so a fine performance tuning can be achieved at the application level. 
Additionally, threads that are waiting for a future can be temporarily reused to process another request, by stacking another method call on it. 
This is also configurable at the application level. 
So to conclude, in ProActive thread creation and thread scheduling are almost completely exposed to the programmer, allowing him to have a great control on the performance of ProActive applications.

\paragraph{Data sharing and object referencing}
% LUDO: I shhortenned the part that was common with ASP
like in ASP, ProActive differentiates active and passive objects in a way that is much 
transparent to 
the programmer, except that passive objects are passed by copy when communicated between 
active objects while referneces between active objects can be shared and accessed from 
anywhere.
The first reason for this behavior is that ProActive is based on Java RMI, and Java RMI 
is based on parameters copy.
The second reason is because of distribution: affording a consistent distributed memory 
is too costly for HPC, which is the primary target of ProActive.
Of course data is shared between the several threads of a multi-active object.

This sharing pattern is thus naturally implemented using RMI and Java serialization that 
performs a deep copy of the parameters transmitted between objects. Future and active 
objects are implemented by a proxy that can be passed by referenced and is serialized as 
a reference (without any copy of other objects referenced). The serialization mechanism 
is also used to track the multiple references to the same future and to implement 
efficient future update strategies~\cite{HKRZ:Coregrid:2010}.
%
%In the case of active objects, they can be indeed shared between active objects but this 
%does not imply safety issues since request reception is centralized and request 
%execution 
%is controlled.
%Thus, one way to share an object globally is to turn it into an active object, but this 
%strategy should be unusually used for performance reasons.
%Another aspect of data sharing in ProActive applies within an active object. 
%Since ProActive implements multiactive objects, there is a potential a multi-threaded 
%environment in each active object. 
%Consequently, objects can be shared between several threads living in the same active 
%object. 
%Data protection must be then ensured by the programmer: either by compatibility 
%definition or by classical locking mechanisms.

%Once again, ProActive object referencing is driven by the underlying technology legacy. 
In RMI, remote objects are globally referenced in what is known as the RMI registry: a mapping from remote object names to remote object stubs, that can be copied and used anywhere in order to target the remote object. 
Networking communication is ensured by the rmi protocol. 
Consequently, in ProActive, all active objects are referenced in a RMI registry, and can be accessed this way from any other object communicating through the rmi protocol. 
For objects that are not active objects, traditional Java object references are used as 
they are only referenced within the same active object.
In conclusion, two types of object references exist in ProActive: global references, retrievable from the RMI registry, and local references, manipulable like classical references in programming languages. 

\paragraph{Error handling}
Distributed environments are prone to failures. 
Since ProActive targets distributed environments, a particular effort was made in producing robust ProActive applications by design. 
For that, the ProActive library includes two different error handling aspects. 
First, an exception chaining mechanism was developed on top of RemoteException, which is 
the basic RMI exception, in order to have a readable feedback when ProActive applications 
crash. Also a specific API has been developed to compensate for the difficulty to deal 
with asynchronous exception and the lack of control on the Java exception 
mechanism~\cite{CC-ECOOPWS2005}. 
Another aspect of the ProActive library consists in continuing the execution of the application in presence of some failed active objects, for example if a machine hosting some active objects of the application crashes. 
For this purpose, ProActive implements a  fault tolerance protocol specific to the active 
object semantics. It enables a set of failed active objects to restart  from the latest 
checkpoint. 
The checkpoints are taken per active object, based on the communications between them. 
This strategy is coupled with the logging of events received by the active object, to ensure a deterministic reexecution. 
The fault tolerant protocol is complete for applications that only feature mono-threaded active objects. 
It is under development for applications that feature multiactive objects.

\paragraph{Garbage collection}
Handling garbage collection in ProActive is deeply linked with how objects are referenced. 
Firstly, to ensure garbage collection of regular objects, no particular attention is needed, simply because the given Java garbage collector will take care of them. 
Indeed, as a regular object cannot be referenced by several active objects, it is guaranteed that no reference to this object exists in another JVM, so classical garbage collection is enough.
However, in the case of active objects, we cannot directly know if it still exists a reference to an active object, because many proxies of an active object can be disseminated throughout the network.
An adapted algorithm to garbage collect active objects was developed in ProActive. 
It is based on the detection of useless active objects (those that are idle and only 
referenced by idle active objects). This is detected as some form of common agreement 
based on the reference graph between active objects~\cite{CCH:Middleware07}. Garbage 
collection of passive objects can safely rely on the Java garbage collector.

\subsection{ProActive backend for ABS}
\label{subsec:proactive-backend-abs}
The ProActive backend for ABS generates ProActive code 
corresponding to an ABS program. The goal of the ProActive backend is to provide a fully 
working execution of ABS models in distributed environments, with less optimization than 
expected with the Java 8 backend. Since the two languages are based on different active 
object models, the 
main challenges in the translation are (i) how to efficiently support object groups in 
ProActive where there only exist active and passive objects, (ii) how to address objects 
in the translation since objects are passed by reference in ABS and by copy in ProActive, 
and (iii) how to simulate cooperative scheduling with multi-threading controlled through 
annotations. We first present object referencing aspects as scheduling is   
dependent on the set of objects that are decided to be active.

\paragraph{Data sharing and object referencing}
In ABS all objects are accessible from all others; thus one could implement all objects 
with a ProActive active object. However, in practice, this is hardly manageable: a 
ProActive active object is associated a plain Java thread. Thus, this solution would 
inevitably lead to a substantial memory consumption and context switch overhead.
In the code generated by the ProActive backend, only the COGs are active objects, and thus are the entry points to all the objects they contains. Thanks to this hierarchy, objects other than COG objects remain passive, which preserves the performance of the ProActive backend.
Thus, we have a two-level hierarchical indexing of objects:
 A first level of network-wide accessible COG objects. This mechanism is integrated in 
 ProActive as it is based on RMI~\cite{Wollrath:1996:DOM:1268049.1268066}.
 A second level of locally accessible objects. This mechanism is implemented in the COG 
 class using a map from object identifiers to object references.
Consequently the 
translation introduces indirections through COGs that can be accesed by remote references.
This configuration of objects is illustrated on Figure~\ref{fig:ABS-to-PA-new}, where a new COG is created through a new \code{Server} object.

\begin{figure}[t]
		\begin{subfigure}[b]{0.43\linewidth}
                 \includegraphics[scale=0.3]{pictures/ABS-to-PA-new.png} 
                \caption{ABS new in ProActive}
                \label{fig:ABS-to-PA-new}
        \end{subfigure}
        \begin{subfigure}[b]{0.50\linewidth}
                  \includegraphics[scale=0.3]{pictures/ABS-to-PA-call.png} 
                \caption{ABS asynchronous method call in ProActive}
                \label{fig:ABS-to-PA-call}
        \end{subfigure}
 \caption{Representation of ABS objects and calls in ProActive} 
\label{fig:graph}
\end{figure}

%\begin{figure}
%	\centering
%	\includegraphics[scale=0.3]{pictures/ABS-to-PA-new.png}
%	\caption{Object organization given by the ProActive backend for ABS when a new COG is created}
%	\label{fig:ABS-to-PA-new}
%\end{figure}

An ABS asynchronous  call is 
thus translated into a generic asynchronous method call on the COG of the targeted 
object; it is then the generic method of the COG which retrieves the targeted object 
thanks to a unique 
identifier, and runs the desired method on it by reflection. 
Figure~\ref{fig:ABS-to-PA-call}
%\begin{figure}
%	\centering
%	\includegraphics[scale=0.3]{pictures/ABS-to-PA-call.png}
%	\caption{Translation of an ABS asynchronous method call in ProActive}
%	\label{fig:ABS-to-PA-call}
%\end{figure}
In ProActive, passive objects are not shared between active objects. Therefore, when a passive object is a parameter of a remote method call, it is copied, whereas in ABS parameters of method call are manipulated by reference.
So when the translation performs a remote method call on a COG, all the parameters are 
copied. For the identifier of the targeted object, the name of the method to run, and the 
primitive values, this 
is not a problem because they are immutable variables. Concerning 
the parameters of the method to run that are reference to ABS objects the different 
parameter passing semantics is still safe but for a different reason.
%% RM
Any access to an object is done through an asynchronous method call on the copy of 
method parameters, those invocations end up in calling the unique original 
version of the created object and their hosting COG. Thanks to this mechanism, the 
initial data sharing of ABS is correctly 
simulated even with the no-sharing philosophy of ProActive because the copied data is 
only used as a reference to the original object.
In the end, when we copy an object from one node to 
another, we only need the identifier of the object to be able to retrieve it in the 
right memory space, and a reference to its COG. All the 
others attributes of the objects can actually be omitted since they are never used when 
copied. This observation allows us to optimize object copy and reduce the amount of 
information that is sent through the network. Consequently, the ProActive backend 
generate 
 programs that copy few data but incur more communications 
than native ProActive applications. Compared to the Java 8 backend for ABS, the ProActive 
backend does not distinguish whether COGs are located on the same machines to optimize 
communications, however this is not a problem since only references are copied.
Also, in the ProActive backend class loading is handled by RMI wheres it is implemented from scratch in the Java 8 backend.

\paragraph{Thread creation and scheduling}
Multiactive objects provide several mechanisms to control the scheduling of requests. The right tuning of those controls allows the ProActive backend to simulate the behavior of ABS cooperative scheduling. 
%In general, we create more threads than supposedly in ABS because, when a thread is handed over to another request in ABS, in fact in the ProActive backend a thread is paused and another one is allowed to continue to simulate the same behavior.
More precisely, we can compare the ProActive backend and the Java 8 backend  on the four 
points explained in Section~\ref{sec:implem-java-8}. On points 1 and 3, the ProActive 
backend also delivers a message per asynchronous invocation, but a single request queue 
exists for all objects in a same COG, whereas in the Java 8 backend, there is a request 
queue per object. Concerning point 2, the Java 8 backend ensures that all objects in the 
same COG compete for one single thread, whereas the ProActive backend creates one thread 
per executing (and paused) requests: it is actually the scheduling associated to 
compatibility annotations that ensures that only one request is progressing at a time; 
this strategy avoids implementing continuations in Java which is difficult because of JVM 
constraints. Finally, on point 4 the Java 8 backend shares a thread pool for many COGs 
whereas in the ProActive backend each COG has its own thread pool. In conclusion, the 
ProActive backend has to handle more idle threads than the Java 8 backend. We explain 
below in more details how we implement ABS preemption constructs in ProActive.

\smallskip
$\bullet$ \textit{Translation of  \code{await} statement on futures.}
%% RM
With multiactive objects, a way to control what happens when a thread switches in 
wait-by-necessity is to specify the kind of thread limit: a hard limit restricts the 
total number of threads existing for a multiactive object instance whereas a soft limit 
only restricts the number of threads that are active (not in wait-by-necessity).
To achieve the request scheduling of ABS, we  declare that the generic method of the COG 
that executes all methods by reflection is 
compatible with itself, which means that many of such methods are allowed run in 
parallel. Additionally, this set of methods has a thread limit of 1, with a soft limit. 
Thus, there is only one active thread at a time that 
serves requests in a COG multiactive object: requests do not run in 
parallel but interleave upon wait-by-necessity. 
%Consequently, this multiactive 
%configuration leads to a similar scheduling as ABS.
	
\smallskip
$\bullet$ \textit{Translation of  \code{get} statement.}
%The translation of the ABS \code{get} statement would have been straightforward if we 
%had 
%not configured the COG class for the translation of the \code{await} statement. Indeed,
%by doing so, 
The problem  is that
we have disabled the blocking aspect of a ProActive wait-by-necessity to handle 
 cooperative thread release upon await statement. 
Consequently, to translate the \code{get} statement we temporarily go back to the initial 
behavior of a ProActive wait-by-necessity and switch the thread limit to a hard thread 
limit so that no 
other request can execute while the get statement is executed. 
%When the future is resolved, 
%we set back the soft limit restore the cooperative scheduling behaviour. 
%% RM

\smallskip
$\bullet$ \textit{Translation of  \code{await} statement on conditions.}
To handle an \code{await} statement on a condition we generate a  method and create an 
asynchronous request (of another compatible group) that checks the condition ane finishes 
when the condition is verified. It is then sufficient to perform an await on the future 
for this request as explained above.
%Another usage of the ABS \code{await} statement is to use it followed by a condition. 
%For 
%translating this kind of \code{await} in ProActive, we wrap the condition evaluation in 
%a 
%method call that returns a future, and we synchronize on it afterwards. More precisely, 
%for each such condition, we generate a corresponding method. Then, we translate the 
%\code{await} statement by an asynchronous call to another generic method of the COG 
%class 
%that is specially devoted to execute waiting conditions, giving it all required 
%parameters to do that. Again, we configure this method with multiactive annotations in 
%order to allow several conditions to run in parallel. 
%We allocate many threads for the evaluation of conditions and reserve through 
%annotations 
%one thread for the generic method execution.  
%%% RM  
%This way, we have a clear separation between the single thread used by application 
%method, and the threads used by the condition execution method.
%%% RM

\smallskip
We have formally proven that all ABS constructs are correctly translated by the ProActive 
backend, more precisely the ASP translation simulates all the rules of ABS 
semantics, and that all translated ASP configurations correspond to a valid ABS 
execution. 
%%%% Without the figures, the text could be like the one below %%%%
%In addition, we have performed two experimental evaluations on an ABS 
%application translated with the ProActive backend, that show that (i) the translated 
%application run in a distributed environment indeed outperforms traditional ABS program 
%execution, and (ii) that the overhead introduced by the translation is always kept under 
%10\% compared to a native ProActive application.
We have evaluated a program generated with the ProActive backend for ABS, and run in 
distributed mode. We have compared it with the same program generated with the old Java 
backend for ABS run on a single machine. We have also compared it with the same 
application written directly in ProActive so that the experiment also illustrate the 
performance of the ProActive library. The chosen use case is oriented towards 
computation: it relies less on active object communications than the experiment presented 
for the Java 8 backend for ABS. Indeed, as ProActive active objects rely on physical 
threads and data copy has to be paid for each communication, ProActive is more adapted to
computational intensive use cases rather than communication intensive use cases.
The considered use case is the pattern matching of a DNA sequence using the MapReduce programming model.%~\cite{Dean:2008:MSD:1327452.1327492}.
Map instances (workers) are created in their own COG to make them work in parallel.
We consider a searched pattern of 250 bytes, and a database of 5 MB of DNA sequences.
Each map searches for the maximum matching sequence of a chunk.
Then, a reducer outputs the global maximum matching sequence.
We compute the global execution time. In ProActive, we instantiate two workers on each 
machine (each machine has two dual-core CPUs). 
%All used machines have 2 dual
%core CPUs at 2.6GHz, and 8 GB of RAM\footnote{We use a cluster of Grid5000 platform: \url{http://grid5000.fr}}.

\begin{figure}[t]
		\begin{subfigure}[b]{0.50\linewidth}
                 \includegraphics[scale=0.31]{pictures/usecase-final.png} 
                \caption{Against existing solution}
                \label{fig:bench-usecase}
        \end{subfigure}
        \begin{subfigure}[b]{0.50\linewidth}
                  \includegraphics[scale=0.31]{pictures/native-final.png} 
                \caption{Against native code}
                \label{fig:bench-native}
        \end{subfigure}
 \caption{Execution time of DNA-matching ABS application${}^{\thefootnote}$} 
\label{fig:graph}
\end{figure}

Figure~\ref{fig:bench-usecase} shows execution time of both ProActive and Java translations of the ABS application from 2 to 50 workers, therefore using from 1 to 25 physical machines with ProActive. 
The execution time of the application stemming from the ProActive backend is sharply 
decreasing for the first added machines and then decreases at a slower rate. On the other 
hand, the application stemming from the Java backend has an optimal degree of parallelism 
of 4 workers (i.e., the number of cores of the machine); execution time even increases 
afterwards due to context switching.
On the opposite, increasing the degree of parallelism for the application stemming from 
the ProActive backend gives a linear speedup, because it balances the load between 
machines. 

Figure~\ref{fig:bench-native} compares  the performance of the generated ProActive code 
to a hand-written version. 
In the generated program, we have manually replaced the translation of functional ABS types 
(integers, booleans, lists, maps) with standard Java types, similarly to the 
code the Java 8 backend produces. 
%Indeed, our point here was to evaluate the additional communication cost of our translation, not the performance of ABS types compared to standard Java types.
%\footnote{As can be noticed on the generated ProActive of Figures~\ref{fig:bench-usecase} and~\ref{fig:bench-native}, there is an order of magnitude of difference depending on the types used; fixing this is  
%on-going~\cite{ref:ABS-Java-translate}.}
The overhead introduced by the transaltion performed by the ProActive 
backend is rather low since it is  kept under 10\% except when many machine are involved 
and the communication rate is too high.
%At the biggest stage, the application translated with the ProActive backend starts to 
%have a higher overhead because it involves too much communication. 

\subsection{Encore}
%\TODO{clean up this introduction}
%explicit bytecode operations?
%particular accent on data sharing since lots of care has been put is designing an efficient data sharing in Encore.

The Encore implementation consists of two major components, a
Source-to-source compiler (from Encore to C) implemented in Haskell, and the
runtime system, 
%which is based on the runtime used by Pony (PonyRT), 
implemented in C.
%The PonyRT has been designed with scalability in mind, using
%lock-free algorithms for this goal, which suits the Encore language.
The Encore runtime stack (Fig.~\ref{fig:encore:stack}) is built around the runtime used
by the Pony language (PonyRT), which provides a fully concurrent
garbage collector~\cite{DBLP:conf/oopsla/ClebschD13} and actor library among other features.
%
The Encore runtime (EncoreRT), extends the PonyRT with new features
such as futures, the \parT{} abstraction, a task library and the notion of
\emph{encore threads} (explained later), among other things. These features
are part of the runtime and therefore, written in C.
%
On top of these libraries rests the Encore Standard Library, which is
written in Encore itself.

\begin{figure}[t]
  \centering
  \includegraphics[width=2.5in, trim=0 4in 7in 0]{pictures/encore-stack}
  \caption{\label{fig:encore:stack} Encore Runtime stack}
\end{figure}

%From now on and, for ease of understanding,
%we will refer to the EncoreRT and PonyRT indistinctively.

\paragraph{Thread creation and scheduling}
In Encore, the runtime has schedulers whose
responsibility is to schedule active objects. Each scheduler owns a queue
of active objects and each active object owns its own mailbox, which contains
messages to process.

On system start-up, the runtime maps physical cores to schedulers,
saving the overhead of creating and context switching over a large number
of threads, although this can be override, if desired, via the command line.
%
Each scheduler runs in a loop, scheduling active objects until the whole program
terminates. In each iteration of the loop, the scheduler performs three procedures.
Firstly, the scheduler pops an active object from the beginning of
the queue. Secondly, it hands over the control to the active object so that it can
process messages in the mailbox, if any. The active object can only process one
message at a time, to ensure fairness. Thirdly, if a message is indeed
processed in previous step, the active object is pushed to the end of the scheduler's queue;
otherwise, the active object is unscheduled due to having an empty mailbox. The
unscheduled active objects are rescheduled if other active objects send
messages to them. Furthermore, in the second step, new active objects could be created, and
they would be pushed to the end of queue belonging to the current scheduler,
to avoid unnecessary synchronization. 
%
Active objects can be migrated from one scheduler to another via work stealing,
which acts as load-balancer. This only happens whenever a scheduler runs out of active objects.


Active objects in Encore are implemented by a lightweight abstraction called \emph{encore thread},
which resembles green threads. Each active object is assigned an \emph{encore thread}
which provides a thread-of-control to the active object, so that it can process messages in its message queue.
This implementation detail, unlike in ProActive and ABS, make Encore capable of
running thousands of active objects in the same machine.

As described in Section~\ref{sec:encore}, when the active object processes a message
and a synchronisation construct is involved, the running method may be paused
until (e.g.) a future is fulfilled and resumed afterwards. Unlike the ABS solution that relies
on creating new threads (section~\ref{sec:implem-java-8}),
Encore opts for handling stacks, which can be attached to \emph{encore threads}. Based on this idea,
the current stack is put aside and a new stack is given to the Encore thread, so that it
can continue running some other or the same active object using the new stack.
To make this process more efficient, Encore has a stack pool that allows reuse of unused stacks. 
Upon fulfilment of the awaiting future, the Encore thread
can continue processing the paused execution and, after finishing, the stack
is collected and returned to the stack pool for future reuse.

%could be paused in the middle, and be resumed when the request service is scheduled
%again. All information living on the stack must be preserved for message
%processing continuation. Currently, Encore runtime fetches a free stack page
%from the stack pool to process next active object, this new stack page is used
%until next pause happen. When message processing finished, the stack page is
%collected and returned to the stack pool for future reuse.

\paragraph{Data sharing and object referencing}

In Encore, active and passive objects are shared by reference, as opposed to
ProActive which performs deep copying of the object (\ref{sec:implem-proactive}). 
In practice this means that sharing large objects in Encore poses no performance issues.
%
On the other hand, care must be taken when sharing passive objects,
as these are mutable by default and, without the use of a proper capability type,
could introduce data races.
%
Active objects are not subject to this problem, they run in an \emph{encore thread}
which provides its own thread of control. 
%
In terms of the capability system, immutable passive objects
are immune of this problem for obvious reasons. 
%
Following this line, a locked mutable passive object provides locking guarantees
on the object, which prevents data races.
%
In a slightly more advanced usage scenario, we might want to share part of the mutable passive
object so that multiple active objects could work on different parts of the same
passive object, concurrently. This would be safe as well.
%
The capability system has been formalised with proofs of soundness and data race
freedom \cite{encore:kappa} and is a work in progress, not available yet in the compiler.

\paragraph{Error handling}

Currently, Encore offers limited support for exception handling. Errors can be expressed
using option types, where \verb|Nothing| could represent the error, and programmers can
pattern match on it.

\paragraph{Garbage collection}

Encore borrows the garbage collection part from PonyRT
with the necessary extension to accommodate future values, which is not available in Pony. Garbage
collection consists of two parts, collecting active objects, which is covered
in~\cite{DBLP:conf/oopsla/ClebschD13}, and collecting passive objects.

\subsection{Erlang backend for Rebeca}
Execution of Rebeca models is done by translating Rebeca models to Erlang code 
\cite{DBLP:journals/scp/ReynissonSACJIS14}. Erlang is a dynamically-typed general-purpose 
programming language for development of distributed, real-time and fault-tolerant 
applications; it provides an actor-based concurrency model. Having the same concurrency 
model, translating Rebeca models to Erlang is realised by direct mapping of language 
constructs as shown in \cite{DBLP:journals/scp/ReynissonSACJIS14}.

\paragraph{Thread Creation and Scheduling}
Actors, as the only concurrent elements of Rebeca models, are mapped to processes in 
Erlang, concurrently executing elements which are extremely lighter than OS-level threads 
(more than 100,000 of them can be run in a single computer) \cite{Erlang-book}. The 
programming facilities of Erlang for developing concurrent applications (i.e., spawn, 
``!'', and receive) allow processes to create new processes and communicate through 
asynchronous message passing. This facilities are used for translating Rebeca models to 
Erlang codes without needing any modification. The generated processes are scheduled 
using the default scheduler of Erlang, called reduction-based scheduler.
%To model the actors scheduler of Rebeca, reduction-based scheduler of Erlang is used. Using reduction-based scheduler, an Erlang process is allowed to execute for a time slice of approximately 2000 reductions before a context switch occurs. A reduction corresponds to the execution of one of the Erlang's built-in functions.% So, a single reduction is not a constant value.

\paragraph{Data Sharing and Object Referencing}
Reserving a dedicated memory space for each process in Erlang, avoids having any shared 
object among processes. Upon communication, the sent message and its parameters must be 
stored in the message bag of the receiver actor which is located in its dedicated memory 
space. %So, a copy of the parameters is stored in the receiver's memory space. %This 
%%mechanism is called copying message passing of Erlang. 
\LUDO{the end is not clear to me}
Although, passing reference of actors using this mechanism does not result in sending the deep-copy of actors and only reference to actors are copied and are sent. The references to actors are allowed to be used for message sending not for sharing data of actors.

\paragraph{Error handling}
In the current version of Rebeca, there is no mechanism for exception handling and the 
programmer must rely on traditional messages to deal with errors. %So, modelers have to 
%handle exceptions manually. In other words, exception handling is not a special case in 
%Rebeca models and they must be implemented the same as ordinary parts of message servers 
%of actors.
%Currently, Rebeca doesn't have support for exception handling. 
%Codes for handing errors must be implemented the same as ordinary parts of message 
%servers of actors.


\paragraph{Garbage collection}
Rebeca borrows the default garbage collector of Erlang without any modification, which 
runs one garbage collector for each process. %It uses general garbage collection 
%algorithm (dividing memory to young and old generations) for each process. 
\LUDO{I do not understand the last two sentences}
This way, as each Rebeca actor is mapped to one Erlang process, we can say that per actor garbage collection takes place in translated codes. %In addition, the intra process garbage collection only analyses large processes (i.e., processes which consumes more than 20K of memory). So, 
In memory pressure, all of the Rebeca actors are analyzed to this aim as they are long-lived large processes.

\section{Lessons Learned and Conclusion}

\JS{There is an increased parallelism in new active object programming languages. 
They bring new challenges such as efficient data sharing: more work is dedicated to mix and find a balance between data copy and safe shared memory. 
Latest active object languages also take more into account distribution of the the code, and consider data locality. 
Such languages do not systematically assume that there exists a global memory, which then lead to more efficient implementations of those languages.
In this paper, we have showed many implementations of active object languages, and even several of them for the same language semantics (e.g. ABS backends). Those implementations are not simply a duplication for different technologies: each of them is targeted at a particular execution context and at particular use cases where they perform the best compared to other implementations.
Throughout the description of implementations for the presented languages, we could perceive the good point for each of them. Typically, ProActive, the Java 8 backend for ABS, the ProActive backend for ABS, and Encore are the languages and implementations that target efficiency of the program execution. However, each of them address efficiency with a different approach. ProActive programs clearly target HPC applications: setting the program environment is heavy but the distributed execution is efficient on the whole; in particular, a few active objects coexist in the application. The Java 8 backend for ABS provides light threads and enables instantiation of many active objects on the same machine. It also allows active objects to achieve faster communications than in ProActive. At a finer grain, Encore provides optimized constructs with an efficiency of the program at a low-level. On a completely different aspect, Rebeca and ABS by itself have a wide range of verification tools and are not much concerned by the program execution but rather by the program properties. It does not mean that bridging the gap between those two categories of languages is useless, on the contrary it allows program verification and program efficiency to be reconciled and to benefit to a large range of programmers.
}

%\input{survey-parts/introduction.tex}
%\input{survey-parts/example.tex}
%\input{survey-parts/conclusion.tex}

% Appendix
%\appendix
%\section*{APPENDIX}
%\setcounter{section}{1}
%In this appendix,...

%\appendixhead{ZHOU}

% Acknowledgments
%\begin{acks}
%The authors would like to thank Dr. Maura Turolla of Telecom
%Italia for providing specifications about the application scenario.
%\end{acks}

% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{2015-active-objects-survey,biblio,envisage,rebeca}
                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012

% History dates
%\received{February 2007}{March 2009}{June 2009}

% Electronic Appendix
%\elecappendix

%\medskip

%\section{This is an example of Appendix section head}

\end{document}
% End of v2-acmsmall-sample.tex (March 2012) - Gerry Murray, ACM



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
