% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

\documentclass[prodmode,acmtecs]{acmsmall} % Aptara syntax

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\usepackage{tikz}
\usepackage{parcolumns}
\usepackage{listings,multicol}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}
\usepackage{listings}
\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\TODO}[1]{\textcolor{red}{\textbf{[TODO:#1]}}}
\newcommand{\NOTE}[1]{\textcolor{blue}{\textbf{[Note:#1]}}}
\newcommand{\parT}{\texttt{ParT}}
% Metadata Information
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}


% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\doi{0000001.0000001}

%ISSN
%\issn{1234-56789}

% Document starts
\begin{document}

% Page heads
%\markboth{G. Zhou et al.}{A Multifrequency MAC Specially Designed for WSN Applications}

% Title portion
\title{A Survey of Active Objects and Actors}
\author{To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}
To fill
\affil{To fill}}
% NOTE! Affiliations placed here should be for the institution where the
%       BULK of the research was done. If the author has gone to a new
%       institution, before publication, the (above) affiliation should NOT be changed.
%       The authors 'current' address may be given in the "Author's addresses:" block 
%(below).
%       So for example, Mr. Abdelzaher, the bulk of the research was done at UIUC, and he 
%is
%       currently affiliated with NASA.

\begin{abstract}
the abstract
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
%\begin{CCSXML}
%<ccs2012>
% <concept>
%  <concept_id>10010520.10010553.10010562</concept_id>
%  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%  <concept_significance>500</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010575.10010755</concept_id>
%  <concept_desc>Computer systems organization~Redundancy</concept_desc>
%  <concept_significance>300</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010553.10010554</concept_id>
%  <concept_desc>Computer systems organization~Robotics</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
% <concept>
%  <concept_id>10003033.10003083.10003095</concept_id>
%  <concept_desc>Networks~Network reliability</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
%</ccs2012>  
%\end{CCSXML}

%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

%
% End generated code
%

% We no longer use \terms command
%\terms{Design, Algorithms, Performance}

\keywords{Active objects, actors, concurrency, distributed systems}

%\acmformat{Gang Zhou, Yafeng Wu, Ting Yan, Tian He, Chengdu Huang, John A. Stankovic,
%and Tarek F. Abdelzaher, 2010. A multifrequency MAC specially
%designed for  wireless sensor network applications.}
% At a minimum you need to supply the author names, year and a title.
% IMPORTANT:
% Full first names whenever they are known, surname last, followed by a period.
% In the case of two authors, 'and' is placed between them.
% In the case of three or more authors, the serial comma is used, that is, all author 
%names
% except the last one but including the penultimate author's name are followed by a comma,
% and then 'and' is placed before the final author's name.
% If only first and middle initials are known, then each initial
% is followed by a period and they are separated by a space.
% The remaining information (journal title, volume, article number, date, etc.) is 
%'auto-generated'.

%\begin{bottomstuff}
%This work is supported by the National Science Foundation, under
%grant CNS-0435060, grant CCR-0325197 and grant EN-CS-0329609.
%
%Author's addresses: G. Zhou, Computer Science Department,
%College of William and Mary; Y. Wu  {and} J. A. Stankovic,
%Computer Science Department, University of Virginia; T. Yan,
%Eaton Innovation Center; T. He, Computer Science Department,
%University of Minnesota; C. Huang, Google; T. F. Abdelzaher,
%(Current address) NASA Ames Research Center, Moffett Field, California 94035.
%\end{bottomstuff}

\maketitle


\TODO{TODO LIST}


Historical description -- Frank and Einar

Check the dimensions (sec 3.1) -- Frank

implementation sections -> 20 January

- proactive -- 20 jan -- Justine+Ludo

- proactive backend for abs -- 20 jan -- Justine

- java 8 backend for abs (20 jan) -- Vlad

- other backends for abs (end jan) -- vlad

- Encore description -- 10 Jan -- Kiko and Albert

- Encore implementation -- end Jan Kiko and albert

refine implementation dimensions -> 20 jan -- Ludo

use PA and ABS as a template to describe Rebeca -- End January -- marjan and ehsan



\NOTE{Page limit is 35 pages}
\NOTE{To keep in mind: do we include formal semantics of the presented languages?}

\section{Introduction}

A global introduction to the common problems in programming distributed systems. Safety 
issues, common bugs and efficiency issues. A first overview of the families of 
programming models for concurrent and distributed systems. What is difficult? What 
features are important in concurrent? in distributed systems?

Definitions of the important notions like what is an actor or what is a future from a 
(old) historical point of view

\section{Active object Languages}

\subsection{An historical view of Actor and active-object languages}
Actors, Creol \cite{JOY06:creol}, JCobox, 

	Requirements in the design of those languages


Plus a small (or bigger) note on : JAC, 
AmbientTalk, E programming language, Erlang, 
Kilim, Scala actors, Akka, Go,
Panini [Reinar]

\TODO{Not sure all of them should be cited but we will decide later}

Where do we put modern languages like Akka?



\subsection{Dimensions of Comparison between Languages}
Before presenting in details different active object languages, we would like to 
define in this section the key points we are interested in, regarding the design and the implementation of concurrent programming languages in general. 
Those dimensions of comparison, defined below, will then be used in the following of 
the paper to articulate our study.

\paragraph{Objective of the language} Identifying the objective of the language, for
which purpose it was created, is the first step to take for language comparison. 
Indeed, this underlying motivation for language creation will often explain the 
language design choices. For example, the performance of the language can be a crucial factor 
for which another aspect can be neglected, such as the accessibility of the language to non-
experts. Or, a high expressiveness can be expected for a language targeting several 
platforms. Having a precise context for a language often forces to define a trade-off between 
several objectives and for this reason, 
in the following each language description 
will start by a brief presentation of the language's objectives.

\paragraph{Degree of synchronisation} 
	The way a concurrent programming language is  designed highly 
	depends on the degree of synchronisation that can be expressed in it. Each language has a 
	different set of synchronisation primitives, although for active object languages, 
	there is a narrow set of such primitives. In some languages, inspired from pure actors, there is no synchronisation primitive: concurrent entities evolve in a completely 
	asynchronous manner and there is no particular instruction waiting for some event to happen. The 
	only synchronisation between processes is based on the fact that a message can only be 
	received and taken into account after it has been sent; nothing based on the ordering of the messages can be inferred. In this case, a forged synchronisation 
	can be obtained by choosing the set of messages an actor can handle at a given point 
	in time. On the other hand, many active object languages use futures as a synchronisation mechanism. 
	A future represents a
	result that has not been computed yet. When the result is computed, it can be 
	automatically available or explicitly retrieved, depending on the language design; we then say that the
	future is \emph{resolved}. A process can also block waiting for a future to be resolved.
	In active object languages, futures represent the result of asynchronous 
	invocations, and, in most of active object languages, an access to a future is a strong synchronisation point
	between concurrent entities. This strong synchronisation point makes 
	programming easier as it keeps a sequential workflow that the programmer can trust.
	Several active object languages also support cooperative scheduling: a thread can be 
	suspended (to handle another message) and resumed later. In such 
	languages, the suspension can be triggered when checking the state of a future, whether 
	it is resolved or not. This breaks the sequential processing of messages and requires a 
	better concurrent expertise from the programmer, but also allows him/her to write 	
	programs that are more efficient and less deadlock-prone.

	\paragraph{Degree of transparency} Another difference between languages 
	with concurrency constructs is the number and the complexity of the programming abstractions the programmer has to 
	know and master; among them some are explicitly visible in the program and some are 
	hidden from the programmer, in which say we say that they are transparent. For example,  some active object languages 
	feature transparent asynchronous method invocations, i.e. asynchronous method invocations that are 
	syntactically identical to synchronous ones. Some active object languages also feature transparent futures, which means that, on one hand
	variables which contain futures are not explicitly distinguished with a special static type, and on the other hand, that there is no 
	explicit instruction for accessing a future: an access to a future object is blocking 
	if the future is not resolved yet.
	In general, the more transparency of an active object language, the easier it is to write 	basic programs, 
	because the programmer do not need to know all the intricacies of the 
	programming model and because the parallelism can be provided automatically. However, when targeting 
	more complex applications, the benefits of transparency is weakened, as exposing 
	the programmer to all the programming abstractions that are used can make debugging 
	or optimization easier. 
	

	\paragraph{Degree of data sharing} Data sharing is a crucial aspect of concurrent and 
	distributed programming. Depending on the target application domain and the potential 
	for distributed execution, the constraints regarding data sharing can be very strong and 
	go against what would be natural in another context. 		
	Indeed, the most efficient way to communicate data between 
	different cores of the same machine is generally sharing, whether in a distributed 
	setting, copying the information to the different consumers of the data is often the most 
	efficient as it avoids peaking the data source, that can be physically far. 	
	Aside runtime efficiency, the complexity of the language implementation varies 	
	accordingly to the degree of data sharing it provides. For example, copying data raises the problem of 
	data consistency as data modifications may not be reflected on all copies.  
	But on the other hand, shared data access involves additional communication to the shared memory, which  
	involves additional synchronisation and delays. In practice, active object and actor languages that have distributed runtimes often use a ``no shared memory'' approach that favors 	
	data copies for objects in general, and that accepts a few entities that are globally known and shared. In other active object languages where all objects are shared, the advantage is that the manipulated programming model is simpler, but 
	the communication overhead is high, especially when programs are run in distributed 
	settings. 
	%Encore is probably the richest language from this point of view, aiming at a 
	%precise control of data sharing including entities that can explicitly be shared 
	%between different actors.

	\paragraph{Formal semantics and support} In order to reason on the 
	properties of a language, a formal semantics for this language is required. Most of the 
	active object languages have a well-defined formal semantics; this is probably due to the fact that the active object and actor models were designed to make concurrent entities run safer, so a formal semantics is needed to formally define their behaviour. Formal semantics 
	can then be used in several ways, either to prove generic properties on the language 
	and provide the programmer with guarantees, as well as to prove the correctness of some 
	implementation or some optimisations, or to implement formal tools for the analysis 
	of programs. A language that is defined with a formal semantics is likely to be more trustworthy, and we believe that having strong fundamental basis facilitate also the language expansion and thus its lasting quality; this is why we also take this point of comparison into account. 
	
	\paragraph{Implementation and tooling support} As a last point of consideration, we believe it is important to 
	compare the active object languages relatively to the related support tools they 
	provide. Indeed, the implementation of an active object language, whether as a 
	complete language or as an API in another language, is an additional factor to 
	take into account because it will determine also the inherited constraints that 
	apply to the underlying technologies that are used. Finally, the tooling support 
	around a programming language ranges from utilities to help the programmer 
	designing, writing, and 
	analysing their programs, to utilities to support the deployment and execution of these 
	programs. This point of comparison meets the previous one to ensure the sustainability of the programming language.

\subsection{A Focus on Some Active-object Languages}

\NOTE{perhaps we should distinguish imlpementation and verification tooling}
\subsubsection{Rebeca}
\subsubsection{ABS}

\lstset{ morekeywords={module,export,import, from, interface, class,
    implements, await, get, new, local,release, suspend} }

\paragraph{General presentation and objective of the language} ABS (\emph{A}bstract
\emph{B}ehavioral \emph{S}pecification) \cite{JHSSS10} is an
object-oriented, concurrent modeling language developed since 2009 in
a series of EC-funded research
projects.\footnote{\url{www.hats-project.eu},
  \url{www.envisage-project.eu}} Its ancestors include \textsc{Creol}
\cite{Elinar2006} and \textsc{JCoBox} \cite{SchaeferP10b}.

In contrast to design-oriented or architectural languages, ABS code is
fully executable. There is a simulator as well as several code
generation backends (at the moment, for Java, Haskell, and Erlang. At
the same time, ABS abstracts away from features that make automatic
analysis difficult in mainstream programming languages. For example,
ABS has an object model, but it does not support code inheritance and
it enforces programming to interfaces as well as strong
encapsulation. It retains, however, modeling features that are
essential in realistic applications, for example, aliasing and
unbounded object creation.

The main design goal of ABS was to create a language that permits to
specify complex behavior of concurrent objects in a concise, natural
manner, while keeping automated analysis of that behavior feasible and
scalable. 

There are extensions of ABS to model product variability
\cite{HHJLSSW12} as well as time and other resources
\cite{johnsen15jlamp}, but these are considered to be out of scope of
the present article.

\begin{figure}
  \centering
\begin{tikzpicture}[scale=1]\small
\node[rectangle, 
          ,shading=axis,shading angle=180,top color=white,bottom color=black!25, line width=2pt,
          minimum width=9cm, minimum height=.6cm, draw] (ass) at (0,4.5) 
          {History-Based Behavioral Interface Specification};

\node[rectangle, 
          ,shading=axis,shading angle=180,top color=white,bottom color=brown!20, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (mod)
          at (0,3.9) {Syntactic Modules}; 

\node[rectangle, 
          ,shading=axis,shading angle=180,top color=white,bottom color=blue!40, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (async)
          at (0,3.3) {Asynchronous Actor-Based Communication}; 

\node[rectangle, 
          shading=axis,shading angle=180,top color=white,bottom color=blue!20, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (cog)
          at (0,2.7) {Concurrent Object Groups (COGs)}; 

\node[rectangle,
          shading=axis,shading angle=180,top color=white,bottom color=green!40, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (imp) at
          (0,2.1){Imperative Language};

\node[rectangle,
          shading=axis,shading angle=180,top color=white,bottom color=green!20, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (object) at
          (0,1.5){Object Model};
\node[rectangle, 
          shading=axis,shading angle=180,top color=white,bottom color=yellow!60, line width=2pt,
          minimum width=9cm, 
          minimum height=.6cm, draw] (exp) at (0,0.9) {Pure
            Functional Programs};

\node[rectangle
          ,shading=axis,shading angle=180,top color=white,bottom color=yellow!40, line width=2pt,
          minimum width=9cm, minimum height=0.6cm, draw] (adt) at
          (0,0.3){Algebraic (Parametric) Data Types};
\end{tikzpicture}
\caption{Syntax layers of the ABS language}
\label{fig:layer}
\end{figure}

\paragraph{Language description} 
In Fig.~\ref{fig:layer} the language layers of ABS are
displayed. Based on parametric (first-order) abstract data types, a
simple, pure, first-order functional language with pattern matching
and strict evaluation is defined. On top of that are objects and a
standard imperative layer. So far, this is very much like
\textsc{Scala}-light.

The central issue for achieving automated, scalable analysis is the
design of the concurrency model. Formal analysis of multi-threaded
languages with interleaving semantics, for example, \textsc{Java},
while principally possible \cite{BlomHuisman14}, is highly complex and
seems to be out of scope at the moment for relaxed memory consistency
models. To achieve feasibility, the concurrency model of ABS carefully
restricts the possible interactions among concurrent tasks while still
allowing to describe complex, realistic behavior of asynchronous
systems.  
%
More precisely, the ABS concurrency model is based on cooperative
scheduling. This means that no task is preempted (interrupted) unless
its modeler explicitly allows to do that. There are two expressions in
ABS that explicitly release control: \lstinline{release} and
\lstinline{await}. The former is unconditional while the latter has a
Boolean argument and can be used to synchronize with another task.

\begin{figure}
  \centering
\begin{lstlisting}[numbers=left,xleftmargin=4ex,escapechar=\%]
module Services;
import Data, init, modify from CustomerData;

interface Server {
  Unit process(Fut<Data> fd);
}

class Service implements Server {
  Unit process(Fut<Data> fd) {
    await fd?; %\label{abs:process:awaitd}%
    Data rd = fd.get;
    rd.modify(); %\label{abs:process:sync}%
  }
}
{ // main block
Server s = new local Service(); %\label{abs:main:begin}%
Data d = new local Data(); 
Fut<Data> fd = d!init(); %\label{abs:main:init}%
s!process(fd); %\label{abs:main:end}%
}
\end{lstlisting}  
  \caption{A simple ABS model}
  \label{fig:abs-simple}
\end{figure}

%% Besser producer/consumer?

% module Services;

% interface Server {
%   Unit produce();
%   Unit consume();
% }

% class Service implements Server {
%   Int MAX = 17;
%   Int stock = 0;
  
%   Unit produce() {
%     while (True) {
% 	  await stock < MAX;
%       stock = stock + 1;
%       }
%   }
  
%   Unit consume() {
%     while (True) {
%       await stock > 0;
%       stock = stock - 1;
%       }
%   }
% }

% { // main block
%   Service s = new Server();
%   s!produce();
%   s!consume();
% }

We explain the concurrency model of ABS with help of the code in
Fig.~\ref{fig:abs-simple}. The unit of distribution in ABS is a
\emph{concurrent object group} (COG) which can be thought of as a set
of tasks that share a common heap and a single processor. Each task
executes code owned by an object and at most one task is active in a
given COG at any time. New tasks are created by asynchronous method
calls as well as, initially, by selecting the main block of a
module. An example of the latter is the code in
lines~\ref{abs:main:begin}--\ref{abs:main:end}.

Line~\ref{abs:main:begin} declares and creates a new object with
interface type \lstinline{Server} using the implementation in class
\lstinline{Service}.  The directive \lstinline{local} places the
object in the current COG. Without \lstinline{local} a new COG is
created together with the object. The next line declares and creates a
data object (note that interface \lstinline{Data} must be imported) in
the same COG. Hence, \lstinline{s} and \lstinline{d} share the same
heap. Line~\ref{abs:main:init} calls an initialization method
(implementation not shown) on the data. The notation ``\lstinline{!}''
signifies an asynchronous call. Its effect is to create a new task in
the COG of \lstinline{d} that executes the code of
\lstinline{init()}. Asynchronous calls do not interrupt the caller, so
the statement following the call is immediately executed. Therefore,
we need a handle by which to retrieve the result of an asynchronous
call once its result has been computed. In ABS the type of such
handles have a future annotation. As can be seen in
Line~\ref{abs:main:end}, it is possible to pass futures as
parameters. This makes it possible to use the result of an
asynchronous call in different places without copying it.

After execution of the main block finished, two tasks in the current
COG are waiting, corresponding to the calls to \lstinline{init()} and
\lstinline{process()}, respectively. None of them could have started
while the main block was still executing, because there was no
synchronization expression in the latter. ABS does not determine which
of \lstinline{init()} and \lstinline{process()} is started first. In
fact, ABS can be parameterized with different scheduling
strategies. The static analyzers of ABS take all possible scheduling
sequences into account.

A first synchronisation point is reached in
Line~\ref{abs:process:awaitd} of \lstinline{process()}. It ensures
that the value of the future \lstinline{fd} is available. If
\lstinline{init()} had not been scheduled before, it will be now. Once
the value of \lstinline{fd} is available, it is retrieved with a
\lstinline{get} expression. Note that \lstinline{rd} and \lstinline{d}
might well be aliased. The standard ABS idiom for asynchronous calls
in ABS is as follows:

\begin{center}
  \lstinline{Fut<T> fx = o!m(); ... ; await fx?; T x = fx.get;}
\end{center}

In many cases \lstinline{await} and \lstinline{get} follow an
asynchronous call directly. For this common sitation the abbreviation

\begin{center}
  \lstinline{T x = await o!m();}
\end{center}

is provided which avoids the declaration of an explicit future.

Line~\ref{abs:process:sync} contains a synchronous call which is also
possible in ABS. It results in sequential behavior, i.e., yields the
processor to the callee and blocks the caller until it
returns. Obviously, here we are interested only in the side effect
that \lstinline{modify()} has. Synchronous calls are only permitted in
the COG of the caller object.

\paragraph{Degree of synchronisation} 
If one attemps to retrieve a future value that is not yet ready, this
results in blockage of its COG until the value becomes
available. Obviously, this can easily lead to deadlocks. Many
deadlocks can be avoided by guarding \lstinline{get} expressions with
an \lstinline{await} (Line~\ref{abs:process:awaitd}). Clearly, not all
deadlocks can be prevented in this manner. In practice, however,
deadlocks are easy to avoid, because synchronisation points are
explicit. In addition, ABS comes with an automated deadlock analysis
tool for ABS \cite{CGM:SoSym2014} that detects all potential
deadlocks.  An important point is that between explicit
synchronisation points (\lstinline{release}, \lstinline{await}) no
data races can occur and computations are, therefore, deterministic.

\paragraph{Degree of transparency}

ABS is an abstract language and implementation-specific aspects
including scheduling, message queueing, object representation are
hidden from the modeler. Abstract data types and interfaces can be
used to postpone detailed design decisions while still permitting
analysis of those aspects of a model that are fully specified.

\paragraph{Degree of data sharing}

Between different COGs no data sharing is possible. The attempt to
call a method in a remote COG with a local class argument results in a
runtime error. Within the same COG all tasks have acess to a common
heap and can modify shared data. However, objects have strictly
private visibility, that is, they can only directly access their own
fields. The fields of any other objects must be accessed by explicit
method calls (getter/setter methods).

\paragraph{Formal semantics and support}

ABS has a fully formal, small step operational semantics
\cite{hats-d1.2} that permits formal soundness theorems for the
various analyses that are available for ABS. This semantics is
directly expressed in terms of rewrite rules in \textsc{Maude} format
\cite{ClavelDELMMT07} which yields a sound interpreter for ABS.

In addition there is an axiomatic semantics in the form of a program
logic~\cite{ref:key}. The behavior of interfaces and classes can be
specified by invariants over the histories of symbolic states as contracts 
between processes. 
Because preemption is excluded in ABS it is sufficient to establish
invariants upon object creations, at explicit synchronisation points and 
upon the termination of methods.  It is possible to prove a composition 
theorem for ABS about the relation between local and global invariants
\cite{Din14fac}. This makes it possible to prove global behavioral
properties of an ABS model by (method-)local reasoning.

\paragraph{Implementation and tooling support}

As ABS has been developed with the goal of being analysable, there is
a wide range of tools available. Most of them support the full ABS
language and are fully automatic. An overview of several of the tools
is available as \cite{BFH14,WongAMPSS12}.

There is an \textsc{Eclipse} plug-in that provides a development
environment for ABS and integrates most tools, see
\url{http://tools.hats-project.eu/eclipseplugin/installation.html}. An
alternative is the web-based ABS collaboratory at
\url{http://ei.abs-models.org:8082/clients/web/} which requires no
installation and also permits to try out most ABS tools.  Here is a
list of currently supported tools for ABS:

\begin{itemize}
\item editor with syntax highlighting and integrated build system,
  including compiler error location;
\item simulator/interpreter with interactive debugger;
\item visualization of ABS model execution as sequence diagram;
\item code generator backends for Erlang, Haskell, ProActive~\cite{rochas:hal-01065072}Java
  8~\cite{serbanescuNABN14a};
\item a glass box test case generator for \emph{concurrent} models \cite{AlbertAGM15};
\item a sound deadlock analysis \cite{CGM:SoSym2014};
\item a worst-case resource analysis that can be parameterized with a
  cost model for execution time, memory consumption, transmission
  size, peak cost and various other cost categories \cite{AlbertAFGGMPR14};
\item a deductive verification tool for expressive, history-based
  property specifications \cite{ref:key}
\end{itemize}


\subsubsection{ProActive and ASP}
\paragraph{General presentation and objective of the language}
ASP~\cite{ref:asp} is an active object programming language especially designed for
programming and deploying distributed systems. ProActive is a Java library implementing the semantics
of the ASP calculus. The language is designed taking the constraints of distributed
programming into account, and relies on Remote Method Invocation as the communication layer even though
other communication mechanisms can be used. ProActive is intended for distributed execution; it
is a middleware that supports application deployment on distributed infrastructures such
as clusters, grids and clouds. Several choices for the design of the language can be
explained by these practical concerns.

One of the design choices for ASP and ProActive is to ensure maximal transparency for the 
programmer: active objects and futures are manipulated like usual Java objects. The 
ProActive middleware automatically triggers asynchronous remote invocations and performs automatically blocking synchronisation when 
needed. ProActive is thus intended to Java programmers that are not particularly experts in concurrent and distributed programming. 

Since 2010, ASP features
\emph{multi-active objects}~\cite{HHI2013:mao} meaning that in each active object, several
threads can run in parallel and process several requests of this active object, but each thread is still isolated inside a single activity. 
Such multi-active objects feature at the same time local concurrency and global 
parallelism.

\paragraph{Language description}
In ASP, active objects coexist with objects that are not active; we call them 
\emph{passive} objects. An active object together with its 
service thread(s) its passive objects, and its request queue is called an activity. 
Each passive object is placed under the responsibility of an active object.
Only active objects are accessible between activities. The 
objects that are not active are only accessible within an activity; if those 
objects need to be used by several activities, they are copied in each activity. Based on this 
clear separation, the activity is the unit of distribution, which matches the usage of one memory space per activity. 
In ASP, when using multi-active objects, 
several threads can execute in the same activity, thus several threads can potentially access the objects of an activity. 

The language is transparent: method calls are automatically turned into asynchronous 
requests if the targeted object is a remote active object, otherwise it is a synchronous, local method call. Similarly, futures are 
implicitly created upon asynchronous calls. Futures are also transparently manipulated: 
a wait-by-necessity is automatically triggered upon an access to an unresolved future. 
In ASP, futures are first-class: they can be passed between activities. In this case, 
when the future is resolved, the result is automatically updated at all locations.

ProActive offers an API to create active objects, 
and a runtime for handling ASP features. The following is an example of ProActive program:
\lstset{
	emph={parameters,node}, 
	emphstyle=\itshape
} 
\begin{lstlisting}
O o = PAActiveObject.newActive(O.class, parameters, node);
T t = PAActiveObject.newActive(T.class, parameters, node);
V v = t.bar(); 	// implicit asynchronous method call
o.foo(v); 	// v can be passed without blocking
v.foobar(); 	// potential wait-by-necessity on v
\end{lstlisting}
%%% THE FOLLOWING MIGHT BE TOO DETAILLED %%%
 An active object is created using \code{newActive}, instead of the \code{new} of Java.
 The \code{newActive} primitive takes as parameters the class to instantiate, the parameters of the
 constructor, and the node on which the active object will be deployed.
 The variable \code{v} is the result of an asynchronous call; it is an
 implicit future.
% The dynamic type of \code{v} is a future that is a dynamically created subtype of 
%\code{V}. 
 When the future value is needed to continue execution, such as in \code{v.foobar()}, 
 a wait-by necessity automatically occurs if the future is not resolved. In ProActive,  
 proxies are used to handle transparently active objects and futures.
% In ProActive, when an active object is created, it is registered in the
% RMI registry delivered with Java. A local reference to this active object is also created: 
% a proxy that delegates invocations to the active object.

 The principle of the multi-active object programming model is to execute multiple
 requests of an active object in parallel, while controlling the concurrency. 
 In practice, the 
 programmer can declare which requests (i.e. which methods of the active object) can be 
 safely executed in parallel. Such requests are 
  called \emph{compatible} requests. The internal scheduler of an active object will allocate by default
 as many threads as necessary to run compatible requests in parallel.
  In 
 ProActive, multi-active object features
  can be used through a metalanguage, based on Java annotations. The 
 following is an
 example of multiactive object annotations in ProActive: 
 \lstset{morekeywords={@DefineGroups,@Compatible,@DefineRules,@Group,@MemberOf} }
\begin{lstlisting}
@Group(name="group1", selfCompatible=true)
@Group(name="group2", selfCompatible=false)
@Compatible({"group1", "group2"})
public class MyClass {
  ...
  @MemberOf("group1")   
  public ... method1(...) { ... }
  
  @MemberOf("group2")   
  public ... method2(...) { ... }
}
\end{lstlisting}
In this example, two groups of requests are defined, each of them holding one method. 
The two groups are declared to be compatible (so as their method, by extension). The 
\code{selfCompatible} parameter defines whether two different requests of the same group 
are allowed to run in parallel. At runtime, a ready request is automatically executed if 
it is compatible with requests that are already executing and with older requests in the 
queue (to avoid starvation). 

Without annotations, a multi-active object is a mono-threaded active object, 
without 
any local parallelism nor any possible race condition. Programming a mono-threaded active object-based application with ProActive is thus extremely simple. If some 
parallelism is desired, a compatibility should be declared between requests 
that can be safely interleaved and for which execution order do not matter.
To define a compatibility between two requests, the programmer can also use runtime information such as the request parameters or the object's 
state. Programming a multi-active object-based application with ProActive is thus a bit more difficult than programming mono-threaded ProActive active objects, but it is less complicated than programming with raw threads and low-level synchronization mechanisms while giving a competing parallelism compared to those ancient techniques.
However, if even more parallelism, out of the scope of request compatibility, is required, the programmer can still define more requests as compatible, and prevent unexpected behaviours with traditional low-level Java synchronisation 
primitives, this mixed approach goes beyond the traditional 
active-object model.

Other high-level specifications are available in multiactive
objects~\cite{henrio:hal-00916293}, such as request priority. To avoid thread explosion,
it is also possible to set a limit on the number of threads running in parallel.  The
limit can be applied in two ways: a hard limit restrains the overall number of threads
whereas a soft limit only counts threads that are not in wait-by-necessity. 
Additionally, threads can be limited per group.

As a conclusion, ASP and ProActive are based on the multiactive object programming
model.
This model is well adapted to non-expert because it provides high-level features for distribution 
and safe concurrency.

\paragraph{Degree of synchronisation}
In ASP, the only blocking synchronisation is the wait-by-necessity on a future. In this case, as requests run until completion, potential deadlocks can arise in 
case of reentrant calls, especially if no compatibility annotation is specified. 
However, synchronisation only occur when the future value is actually needed and, in 
particular, future references can safely be transmitted between activities without 
requiring any additional synchronisation, which limits blocking synchronisation leading to deadlocks.
Another form of synchronisation exists in the sense that, when a thread becomes in wait-by-necessity, it is not counted in the soft thread limit of the active object any more, so the wait-by-necessity event is potentially coordinated with the start of another request.

\paragraph{Degree of transparency}
In ASP the programmer is not explicitly exposed at all to the notion of future and in a moderate way to the notion of active object (at active object creation time only). The syntax is the same as the syntax for sequential 
programming, there is no specific construct for waiting a future value or performing an 
asynchronous call. Very often a sequential code can be reused unchanged in a distributed 
setting.

\paragraph{Degree of data sharing}
ASP follows a strict policy of absence of sharing between active objects. Objects that are 
not active objects and are passed by copy between activities (as request parameters or request 
results). Of course this mechanism applies also to objects that referenced by passed 
objects; a deep-copy mechanism is used ensuring that, when objects are transmitted 
between activities, they are copied as well as all their dependency on the destination 
side. This mechanism, which is the one used by RMI, slows down request invocation in practice because 
of the time spent to transmit data, but accelerates request treatment because there is no 
need to contact another activity to get the value of the request parameters.

There is no coherency ensured between the different copies of a passive object, thus if 
the user wants to ensure that an object has a unique coherent state, he should not 
transmit it by copy, and in this case transmitting an active-object reference instead would be the best choice.

\paragraph{Formal semantics and support}

Several papers formalise the semantics of ASP. The first of them formalised the 
mono-threaded part of the language and proved some determinacy 
properties~\cite{CHS:POPL04}. In particular, this paper proved that the order of future 
updates has no influence on the execution and that the only source of non-determinacy in 
mono-threaded ASP is when two activities can send a request to the same destination.
A functional fragment of the calculus has also been 
formalised in Isabelle/HOL~\cite{HKL:SCP11}. A specific semantics has been exhibited in 
order to evaluate a functional ASP program without risk of having a deadlock; the absence 
of deadlock has been proved in Isabelle/HOL.
The full semantics of imperative ASP with multi-threaded activities is published 
in~\cite{HHI2013:mao}.

As shown in~\cite{BHR2014:gcm}, ProActive active objects, and active objects in general,
provide a convenient programming model for component based composition of distributed
applications. The ProActive library implements the GCM distributed component model. In
this context, the Vercors
platform\footnote{\url{https://team.inria.fr/scale/software/vercors/}} provides
verification capacities for ProActive components; Vercors consists of an Eclipse plugin
for designing component systems; from this point the Vercors platform can on one hand
verify the correct behaviour of the application using the CADP model-checker, and on the
other hand generate an executable ProActive/GCM code corresponding to the designed system.

\paragraph{Implementation and tooling support}
ProActive is the Java library implementing ASP semantics. 
In ProActive, in order to transparently handle active objects and futures, a proxy is created for each of them. Proxies encapsulate all needed code to perform asynchronous, remote method invocations and wait-by-necessity behaviour. Whenever an active object or a future is given as parameter of a call to an active object,  it is in fact their proxy that is copied. This way, all copies of a proxy of an active object/future points to this same active object/future. 
Another particular aspect of ProActive deals with
the deployment of ASP active objects on distributed infrastructures. The design choices of the programming language typically target a high performance of distributed ProActive applications. 
In order to settle active objects on distributed infrastructures, ProActive features a deployment specification mechanism. The goal of this mechanism is to make the physical deployment independent from the the deployment logic. This is possible by having a binding from virtual node names, used in the source code, pointing to machine addresses or names. In practice, this binding is implemented in XML configuration files. Also, since the binding is made at \emph{deployment time}, changing infrastructure for a given ProActive application is only localised in a few files and does not require application recompilation. 
Several machines can be aggregated under a single virtual node name in the deployment logic, for example to provide the virtual node with some properties or non functional deployment options (such as fault tolerance or logging).


\subsubsection{Encore}

\paragraph{General presentation} Encore \cite{ref:encore}
is a general purpose parallel language based on active objects
developed since 2014 \NOTE{check year} by an
EC-funded research project\TODO{reference to Upscale}. 
The language has been designed to excel at scalability and rests on four pillar concepts: 
\textit{parallel by default} using the
active object paradigm for coarse grain parallelism, \textit{independent
local heaps} to promote data locality, \textit{type-based synchronisation directives}
provided by a novel capability system and \textit{coordination of parallel
computations and low-level data parallelism} via parallel combinators.
On top of these key ingredients, Encore stays loyal to the object-oriented paradigm
where active objects and futures can be seen as normal Java objects and,
instead of interfaces, provides a trait system \`a la Scala.

\paragraph{Language description}
In Encore, active objects have their own thread of control and communicate with each 
other by sending messages. These messages are placed in the receiver's message queue
and processed by the receiver one at a time. This property linearises
the execution of the active object. As in any other
object-oriented language, an active object has attributes and methods.
The active object state is usually model with passive objects. These do not have a thread of control and are
similar to \textit{unsynchronised} Java objects. A passive object lives in an active object's heap
and, if shared with multiple active objects, data races may occur.

Method calls on active objects are asynchronous and return a future value that, unlike ProActive,
has the explicit type \texttt{Fut t}. A future value is a handle to a parallel computation,
has a well defined interface to operate on and is a first class citizen. On the other hand,
method calls to passive objects are synchronous and behave similar to Java objects.

The code from Figure~\ref{fig:encore:example} gives a taste of Encore:

\begin{figure}[ht]
\begin{parcolumns}{2}
\colchunk{
\begin{lstlisting}[numbers=left,xleftmargin=4ex,escapechar=\%,numberblanklines=true, showlines=true]
passive class Data { ... }    

passive class Queue : TQueue
  top: Link

class Main
  def main(): void {
    let buffer = new Buffer()
         data = new Data(21)
    in {
      buffer.put(data);
    }
  }

\end{lstlisting}
}
\colchunk{
\begin{lstlisting}[firstnumber=14,numbers=left,xleftmargin=4ex,escapechar=\%]
trait TQueue
  requires top
  
  def enqueue(x: int): void
    this.top = new Data(x, this.top)

class Buffer
   queue: Queue
   
  def init(): void
    this.queue = new Queue()
    
  def put(item: Data): void
    this.queue.enqueue(item)
\end{lstlisting}
}
\colplacechunks
\end{parcolumns}
\caption{Example of a Buffer implementation that uses traits, active and passive objects in Encore}
\label{fig:encore:example}
\end{figure}

The \texttt{Buffer} class (Figure~\ref{fig:encore:example}) represents an active object with
a private attribute \texttt{queue} of a passive class \texttt{Queue}. This passive class
implements the trait \texttt{TQueue} (line 3 in Figure~\ref{fig:encore:example}). A trait can be
seen as a Java interface with a definition and may require some attributes to exists. For instance,
in line15 the trait \texttt{TQueue}
requires the existence of an attribute called \texttt{top} and, the next line provides the implementation
of the \texttt{enqueue} method. Any passive object of type \texttt{Queue} has an implementation
of methods defined in the traits it extends, in this case, the \texttt{enqueue} method. The \texttt{Main}
class is the entry point of the program and creates an active object (\texttt{buffer}) and some data.
The method call \texttt{buffer.put(data)} returns a future that, in this case, is not used and discarded.

Encore currently provides three operators for controlling execution flow within
and across active objects: \verb|suspend|, \verb|get|, and \verb|await|.
\verb|suspend| suspends the current message processing, appends a resuming
message to the message queue and passes control to the next message in the
message queue (which could be the resuming message if the message queue was
empty). \verb|get| takes a future as its operand, returns the value in the
future. In other words, \verb|get| has type: \verb|get :: Fut t -> t|. Depending
on the status of the future, resolved or not, the control flow change caused by
\verb|get| is different: if the future is resolved, \verb|get| doesn't alter the
control flow at all; on the other hand, if the future is not resolved yet,
\verb|get| would caused the calling active object to be de-scheduled until the
future is resolved. The active object would be resumed at the exactly same
execution point except that the future is resolved, and the call to \verb|get|
returns. Because \verb|get| would stop the whole active object, which might not
always be desirable, \verb|await| is provided so that only current message
execution is paused, but the active object could still process other messages in
the message queue. When the future becomes resolved, a special message is sent
by the resolver of the future to the active object so that the paused message
execution could resume. Let's see an example how each of them behaves in the
following example. (To keep things simple, it's assumed to be run on a
single-core machine or specified to use single Operating System thread.)

\begin{lstlisting}[
  basicstyle=\footnotesize,language=Haskell,
  multicols=2,
  numbers=left,xleftmargin=4ex,escapechar=\%
]
class Agent
  def print_1_3() : void {
    print 1;
    suspend;
    print 3;
  }
  def print_2() : void {
    print 2;
  }
  def produce() : int {
    print 2;
    3;
  }
  def print_1() : void {
    print 1;
  }
  def self_produce() : void {
    let
      it = this
      r = it.produce()
    in {
      await r;
      print get r;
    }
  }
class Main
  def test_suspend() : void
    let
      a = new Agent
    in {
      a.print_1_3();
      a.print_2();
    }
  def test_get() : void
    let
      a = new Agent
      ret_future = null
      ret = 0
    in {
      ret_future = a.produce();
      print 1
      ret = get ret_future;
      print ret;
    }
  def test_await() : void
    let
      a = new Agent
    in {
      a.self_produce();
      a.print_1();
    }
  def main() : void {
    -- call the other two methods like this
    this.test_suspend();
  }

\end{lstlisting}

The \verb|Main| class contains three methods for showing the semantics of each
operator, and the \verb|main| method, the entry point of the program. In the
\verb|test_suspend| method, two messages, \verb|print_1_3| and \verb|print_2|,
are sent to the agent one after the other. The \verb|suspend| operator in
\verb|print_1_3| would suspend the execution of \verb|print_1_3|, and move the
control to the next message in the queue, which is \verb|print_2|. Once
\verb|print_2| is finished, the control would go to the next message, which is
the resuming message created due to \verb|suspend| call in \verb|print_1_3|.
Therefore, the output would be 1, 2, 3, separated by new lines. In the
\verb|test_get| method, the \verb|produce| call would return a future, and
calling \verb|get| on that future (which can be guaranteed to be un-resolved
while running in the single threaded settings) would block the \verb|test_get|
method until the future is resolved. Therefore, the output is 1, 2, 3, separated
by new lines. In the \verb|test_await| method, two messages, \verb|self_produce|
and \verb|print_1|, are sent to the agent. The agent would process them in
order, but in \verb|self_produce|, \verb|await| is called on an un-resolved
future (which is guaranteed to be un-resolved due to the same reason as above),
which pauses the execution, and moves the control to the next message, which is
\verb|print_1|. After that, \verb|produce| message, created inside
\verb|self_produce|, is processed, which resolves the awaited future, and
\verb|self_produce| is resumed. Therefore, the output is 1, 2, 3, separated by
new lines.

Active objects provide coarse grain parallelism via futures but do not offer
many high-level language constructs for low-level coordination of these computations.
In order to unhinge parallel pipeline and data parallelism, Encore incorporates
the \parT{} collection and the parallel combinators.
The \parT{} collection can hold computations that may not have finished and
is represented by the type, \texttt{Par t}, where \texttt{t} represents a polymorphic type. 
Elements of the collection can be normal values and
future values which can be \textit{lifted} to a parallel collection via
\texttt{liftv :: t $\to$ Par t} and \texttt{lift :: Fut t $\to$ Par t} respectively.

The available combinators that operate on the \parT{} collection are:

\textbf{$| \; :: Par \;t \to Par \;t \to Par \;t$,} read as \textit{par} combinator, that creates a new
\parT{} that holds the computations from the first and second expression.

\textbf{$>< \; :: Par \; t \to Par \;t \to Par \;t$,} read as \textit{otherwise} combinator,
that executes the first expression until the returned value is known and, if empty,
starts execution of the second expression.

\textbf{$>> \; :: Par \; t \to (t \to t') \to Par \; t'$}, read as \textit{sequence} combinator,
applies the function to all elements of the \parT{} collection asynchronously -- creating
parallel pipeline parallelism-- and returns a new \parT{} collection.

\textbf{$<< \; :: (Fut \;(Maybe \;t) \to Par \;t') \to Par \;t \to Par \;t'$}, read as \textit{prune} combinator,
starts execution of both expressions in parallel. As soon as there is a value available
in the second expression, this on gets passed to the first expression and all the remaining
computations from the second expressions are ignored.

The \parT{} collection and its combinators have been designed to perform
operations asynchronously without stopping the current thread of execution.
This creates a collection that never blocks and executes operations on demand,
when the values are available. There are more combinators available \cite{ref:encore}
but we have highlighted the most important ones.


\paragraph{Degree of synchronisation}

In Encore, there are two ways for synchronisation, message passing, and
synchronisation by futures. From the message passing perspective, each method
call on active objects could be interpreted as a message transmitting, and
different active objects could communicate and synchronise with each other using
message passing, just like Erlang. The second approach, which is more akin to
Object-Oriented style, is using futures. Each non-void method call on active
objects returns a future, denoted as \verb|Fut| in Encore, and three operations
are defined on futures, \verb|get|, \verb|await|, $\sim\sim>$ (future chaining).
The first two operators would pause the current method execution until the
future is resolved (fulfilled). The difference between them is the former blocks
the whole actor, as discussed and explained in the previous section on flow
control in Encore. On the other hand, $\sim\sim>$ would register a callback
(anonymous function, aka lambda) to the future, continue processing the rest of
the message. The callback would be called with the future contend as the
argument when the future is resolved.

\paragraph{Degree of transparency}

As mentioned above, futures are denoted as \verb|Fut| in Encore, so non-future
variables and future variables are distinguished statically, e.g.\ \verb|int| vs
\verb|Fut int|. In other words, developers must decide which variables are given
which type, and \verb|get| could be use to convert future type to non-future
type (if the content of the future is non-future type, i.e.\ not something like
\verb|Fut Fut int|) by extracting the content explicitly.

\paragraph{Data sharing}
In Encore, active objects are protected by their own thread of control
while passive objects are protected by a \textit{capability} type.
Encore's type system sees passive objects as resources that
are protected by a capability that governs the kind of access to it \cite{ref:encore}. 
A capability is built from a trait and a \textit{kind}. The trait provides the interface-like
feeling of OOP languages while the \textit{kind} states the "protection" that
the interface provides. By changing a keyword, the \textit{kind}, the interface
changes the protection level. For instance, by changing the \textit{kind} from \textit{exclusive}
to \textit{lock-free}, the interface changes the protection from an actor-like to a lock-free implementation.

\paragraph{Formalization and semantics}
The Encore concurrency model has been formalized (\cite{ref:encore}) using
a small step operational semantics. Parallel combinators have been formalized as well
including a soundness proof with the implicit task parallelism model \cite{encore:parallel-combinators-thesis}.
\NOTE{Elias might have a soundness proof for the Capability system?}

\paragraph{Implementation: programming and execution support}
Encore is a relatively new programming language and there is still some
limited tooling support. However, the Encore compiler can emit a
highly understandable C code that when compiled, produces the binary file.
This C code can be analysed and debug using any available tool that
works with the C11 standard. 

The list of currently supported tools is presented below:

\begin{itemize}
\item Emacs and Atom editors with syntax highlighting and compiler error support
\item Support for GDB / LLDB interactive debugger
\item Vagrant support for rapid installation of Encore in a virtual machine
\end{itemize}

\section{Implementation of active objects}
In this section, we take interest in the implementations of the different active object programming models described in the previous section. In practice, the implementation of a programming language can be provided from scratch or can also be given as an API in a more mainstream language. Another way to implement an active object language is to systematically translate any of its programs into another language; this is possible through a language backend: a translator that captures the semantics of the source language. The advantage of this solution is that an active object language can then have several independent backends targeting different execution platforms and, by this means, fitting the largest needs. 

\subsection{Dimensions of Comparison between Implementations}
In any language implementation strategies, several points need to be considered regarding the language runtime and how the implement efficiently the language semantics. We will use those points to compare active object implementations. 
For each active object implementation, we want to address \TODO{update number of points} five points, among them: how threads are created and handled to achieve the right scheduling, how object are referenced throughout an active object-based application and how objects and data are effectively shared. We describe them below.

\paragraph{Thread creation and scheduling}
% Virtual threads %
The active object languages that are implemented on top of an existing programming language have to comply to the constraints given by the underlying programming language. In the case of multi-threading, some underlying programming language feature light thread whereas having something different than a physical thread is impossible in other programming languages (e.g. Java). In this case, one can consider implementing light threads on top of the underlying programming language, for example to handle efficiently the implementation of cooperative scheduling. Featuring light thread is also crucial if the goal of the given active object language is to scale in the number of active objects located on the same machine. 

% Continuations %
This notion of virtual threads is particularly important when implementing an active object language which features cooperative scheduling of requests: a thread then must stop executing when a request is paused and must resume afterwards. This is a programming challenge when it comes to implement this behavior in programming languages that do not support thread serialization, like Java. In this case, questions like the following should be answered: how active objects are mapped to threads? should a request be associated to a thread or not? Should the thread be a physical thread or some thread notion implemented on top of physical threads?

%how active objects are mapped to threads and the scheduling levels within an object and 
%BETWEEN objects

\paragraph{Data sharing}
This point answers to the question how objects are shared between active objects. The cornerstone of active objects is that they encapsulate their state such that active objects are independent from each other. In practice, this requires making copies when objects are exchanged between active objects. However, always copying might not be the most efficient implementation of an active object language. For this reason, some active object implementations have, in addition of active object states, an object pool where all objects or active objects can peek on and use. Such objects of the object pool are often immutable in order not to disturb active object execution. How to efficiently and safely share information between active objects is still an on going challenge and different kinds of data sharing strategies have been proposed in active object implementations.

\paragraph{Object referencing}
In order to be able to communicate, objects and active objects must have a way to reference each other. In particular, to send a request to an active object, one must have a reference to it. Depending on the programming model, objects and active objects can be either referenced or passed by copy. Thus, an adapted way of addressing all kinds of objects must be implemented.
In distributed settings, an efficient active object implementation cannot rely on a global shared memory, because it would be too costly. Thus, a finer grain referencing is often established for distributed implementation of active objects.

\paragraph{Error handling}
Among non-functional features an active object implementation can provide, we can mention how errors are handled. Different level of error handling can be achieved. First, it is relevant for the language implementation to deal with exceptions, as in any high level programming language. In the case of distributed implementations, exception chaining is more complex if not relied on a library. Secondly, active object implementations can offer recovery or rollback mechanisms to answer the question how the system can recover after one or more active objects were lost. This support is particularly relevant for distributed active object implementations, because the failure rate is proportional to the degree of distribution. 

\paragraph{Garbage collection}
Garbage collection is another non-functional feature that an active object implementation can support. This point is important for the active object applications to scale and to be perennial. On most cases, the garbage collecting strategy must be implemented to fit a particular active object language, because relying on the garbage collection of the potential underlying language can only provide a partial garbage collection. Indeed, the true question in the case of active object implementations is when active objects are not needed any more, since they can receive request unexpectedly and from anywhere.
Again, the question is even more complex in the case of distributed implementations because reference counting is scattered.

Below, we review active object implementation and/or backend according to the dimensions of comparison defined above.

\subsection{Java 8 backend for ABS}
proposed structure:

- Scope of the solution
 for what purpose the implementation is optimized
 (performance, modelling, memory, distributed, parallel)

- scheduling of active objects

- Error handling

- compare with old java backend?


\subsection{ProActive}
The ProActive library is all written in standard Java. 
By default, it uses the remote method invocation Java package to implement the communication layer between active objects, although other communication protocols are possible. 
This fact drives most of the implementation singularities mentioned below.

\paragraph{Thread creation and scheduling}
In ProActive, an active object with no compatibility rule defined will be associated to one Java thread to process the requests. 
Furthermore, there is a Java thread to handle request reception in each active object. 
Java threads are mapped to operating system threads, thus ProActive uses at least two threads per active object. 
But as ProActive features multiactive objects, this number can be higher, as the active object scheduler can create Java threads on the fly to process a compatible request. 
As Java threads are pretty heavy, the ProActive scheduler implementation puts a particular effort on optimizing thread usage. 
Firstly, a thread pool is instantiated at active object start-up to ensure a basic thread reuse policy. 
Secondly, when the number of threads is limited at the application level (through multiactive object annotations), the limit literally maps to Java threads, so a fine performance tuning can be achieved at the application level. 
Additionally, threads that are waiting for a future can be temporarily reused to process another request, by stacking another method call on it. 
This is also configurable at the application level. 
So to conclude, in ProActive thread creation and thread scheduling are almost completely exposed to the programmer, allowing him to have a great control on the performance of ProActive applications.

\paragraph{Data sharing}
For data sharing in ProActive, two aspects have to be considered.
First, active objects do not share any object, apart from active objects themselves, that can be shared between active objects.
Each active object has it own set of object references, and it is the only one active object having such a reference to each of them. 
This applies to the active object state, but also to the local references. 
So, in practice, each time an object is part of the parameters of a remote method invocation (on an active object), or part of a return value of such an invocation, this object is serialized on the sender side and deserialized on the recipient side; a copy of it is thus manipulated on the recipient side. 
The first reason for this behavior is that ProActive is based on Java RMI, and Java RMI is based on parameters copy.
The second reason is because of distribution: affording a consistent distributed memory is too costly for HPC, which is the primary target of ProActive.
In the case of active objects, they can be indeed shared between active objects but this does not imply safety issues since request reception is centralized and request execution is controlled.
Thus, one way to share an object globally is to turn it into an active object, but this strategy should be unusually used for performance reasons.
Another aspect of data sharing in ProActive applies within an active object. 
Since ProActive implements multiactive objects, there is a potential a multi-threaded environment in each active object. 
Consequently, objects can be shared between several threads living in the same active object. 
Data protection must be then ensured by the programmer: either by compatibility definition or by classical locking mechanisms.

\paragraph{Object referencing}
Once again, ProActive object referencing is driven by the underlying technology legacy. 
In RMI, remote objects are globally referenced in what is known as the RMI registry: a mapping from remote object names to remote object stubs, that can be copied and used anywhere in order to target the remote object. 
Networking communication is ensured by the rmi protocol. 
Consequently, in ProActive, all active objects are referenced in a RMI registry, and can be accessed this way from any other object communicating through the rmi protocol. 
Then, for objects that are not active objects, traditional Java object references are used.
In conclusion, two types of object references exist in ProActive: global references, retrievable from the RMI registry, and local references, manipulable like classical references in programming languages. 

\paragraph{Error handling}
Distributed environments are prone to failures. 
Since ProActive targets distributed environments, a particular effort was made in producing robust ProActive applications by design. 
For that, the ProActive library includes two different error handling aspects. 
First, an exception chaining mechanism was developed on top of RemoteException, which is the basic RMI exception, in order to have a readable feedback when ProActive applications crash. \TODO{Check what was done for exception handling in PA}. 
Another aspect of the ProActive library consists in continuing the execution of the application in presence of some failed active objects, for example if a machine hosting some active objects of the application crashes. 
For this purpose, ProActive implements a special fault tolerance protocol enabling restart of an application from the latest checkpoint, if an active object is detected as failed. 
The checkpoints are taken per active object, based on the communications between them. 
This strategy is coupled with the logging of events received by the active object, to ensure a deterministic reexecution. 
The fault tolerant protocol is complete for applications that only feature mono-threaded active objects. 
It is under development for applications that feature multiactive objects.

\paragraph{Garbage collection}
Handling garbage collection in ProActive is deeply linked with how objects are referenced. 
Firstly, to ensure garbage collection of regular objects, no particular attention is needed, simply because the given Java garbage collector will take care of them. 
Indeed, as a regular object cannot be referenced by several active objects, it is guaranteed that no reference to this object exists in another JVM, so classical garbage collection is enough.
However, in the case of active objects, we cannot directly know if it still exists a reference to an active object, because many proxies of an active object can be disseminated throughout the network.
An adapted algorithm to garbage collect active objects was developed in ProActive. It is based on \TODO{Explain}.

\subsection{ProActive backend for ABS}
The ProActive backend for ABS is another translator that generates the ProActive code corresponding to an ABS program. This backend allows ABS program to run in distributed environments thanks to the support of ProActive. For that, all ABS concepts are simulated with ProActive, since the two languages are based on different active object models. The main challenges in the translation are (i) how to efficiently support object groups in ProActive where there only exist active and passive objects, (ii) how to address objects in the translation since objects are passed by reference in ABS and by copy in ProActive, and (iii) how to simulate cooperative scheduling with multi-threading controlled through annotations.

\paragraph{Object referencing}
In the translation from ABS to ProActive, we need to define what happens in ProActive when a new ABS object is created. In particular, we need to define the ProActive code that would be equivalent to the ABS new cog statement.
As in ABS objects should be accessible from all others, one could think that implementing all objects with a ProActive active object would meet the requirement. However, in practice, this is hardly manageable: a ProActive active object is associated a plain Java thread. Thus, this solution would inevitably lead to a substantial memory consumption and context switch overhead.
In the code generated by the ProActive backend, only the COGs are active objects, and thus are the entry points to all the objects they contains. Thanks to this hierarchy, objects other than COG objects remain passive, which preserves the performance of the ProActive backend.
Thus, we have a two-level hierarchical indexing of objects:
\begin{itemize}
\item A first level of network-wide accessible COG objects. This mechanism is integrated in ProActive as it is based on RMI~\cite{Wollrath:1996:DOM:1268049.1268066}.
\item A second level of locally-accessible objects. This mechanism is implemented in the COG class using a map from object identifiers to object references.
\end{itemize}
This classification implies that the application always manipulates local references except for COG objects that can be manipulated through remote references.
Consider the following ABS \code{new cog} statement:
\lstset{ numberstyle=\tiny, stepnumber=1, numbersep=2pt, basicstyle=\ttfamily\scriptsize, keywordstyle=\bfseries,
    showstringspaces=false}
\begin{lstlisting}
Server server = new cog Server();
\end{lstlisting}
We translate this single line of code into the following ProActive code:
\begin{lstlisting}
Server server = new Server();			
COG cog = PAActiveObject.newActive(COG.class, new Object[]{Server.class}, node);			
server.setCog(cog);				
cog.registerObject(server);	
\end{lstlisting}
Line \code{1} creates a regular server object. Lines
\code{2-3} use the \code{newActive} ProActive primitive to create
a new COG active object. Additionally to the constructor parameters, ProActive allows to
 specify onto which node the active object should be deployed at runtime.
Line \code{4} makes the local server aware of its COG.
Finally in line \code{5}, due to the ProActive by-copy parameter passing, the server object is copied in the local memory space of the newly created COG, and is thus locally accessible there.  
For other objects created with \code{new} in ABS, the ProActive backend simply registers them locally in the current COG. Consequently, they can be only referenced locally until they are passed.
With this hierarchical referencing,
it is not technically possible to directly run an asynchronous method call on a object that belongs to a different COG, as it is done in ABS, so we need an adapted translation of asynchronous method calls in ProActive.
Consider this ABS snippet:
\begin{lstlisting}
server!start();
\end{lstlisting}
in the ProActive backend, the principle to translate this is to run an asynchronous method call on the COG of \code{server} and then let this method retrieve the server object and run the desired method on it.
More precisely, here is the translation the ProActive backend provides:
\begin{lstlisting}
server.getCog().execute("start", new ABSType(){}, server.getId());
\end{lstlisting}
More precisely, we first retrieve a reference to the COG of the server object by using the local reference of the server object. Note that this copy of server object is not the one we want to reach since it does not lie in the right COG. 
Then, a generic \code{execute} method of the COG class is called on the COG object returned by \code{getCog()}, and this method call is implicitly asynchronous by the nature of the COG object. When the \code{execute} request is run, it uses the identifier of the targeted object to lookup the reference of the server object that is local to the targeted COG, and then run the \code{start} method synchronously on it by reflection. 
In summary, in the ProActive translation of ABS programs, object references are hidden behind COG references, that are globally known in order to give an entry point to local objects. This way, the performance of the generated distributed applications with the ProActive backend can be preserved.

\paragraph{Data sharing}
In ProActive, passive objects are not shared between active objects. Therefore, when a passive object is a parameter of a remote method call, it is copied, whereas in ABS parameters of method call are manipulated by reference.
In particular, when in the translation we run an \code{execute} method call, all the parameters are copied. For the identifier of the targeted object and the name of the method to run, this is not a problem because they are immutable variables, so having many independent copies of them does not change the behavior of the program. Apart from those parameters, the \code{execute} method also copy the parameters of the method to run by reflection.
for example, consider an ABS asynchronous method call like this one:
\begin{lstlisting}
server!start(p1, p2);
\end{lstlisting}
This asynchronous method call has two parameters, \code{p1} and \code{p2}. 
This is translated through the ProActive backend this way:
\begin{lstlisting}
server.getCog().execute("start", new ABSType(){p1, p2}, server.getId());
\end{lstlisting}
When running the \code{execute} method, objects \code{p1} and \code{p2} are copied to be available locally in the targeted COG. Thus, two versions of \code{p1} and \code{p2} exist at this point of execution, so it is not obvious that the copies of \code{p1} and \code{p2} reflect the latest modifications when the \code{start} method is executed, as it is the case in ABS. But in practice, if the \code{start} method uses \code{p1} and \code{p2}, it means that a method is called on them. And we have seen that a method call is translated by dropping a request in the COG that manages the original object. In consequence, any method call on the copies of \code{p1} or \code{p2} will end up in manipulating the original versions of \code{p1} and \code{p2}. Thanks to this mechanism, the initial data sharing of ABS is correctly simulated even with the no-sharing philosophy of ProActive.
In the end, in the ProActive translation of ABS, when we copy an object from one node to another, we only need the identifier of the object, to be able to retrieve it in the right memory space, and a reference to its COG, that is globally accessible. All the others attributes of the objects can actually be omitted since they will not be used when copied. This observation allows us to optimize object copy to reduce at minimum the amount of information that is sent through the network. In summary, the ProActive backend generate ProActive programs that copy few data but that, in return, incur more communications.

\paragraph{Thread creation and scheduling}
Multiactive objects provide several mechanisms to control the scheduling of requests. The right tuning of those controls allows the ProActive to simulate the behavior of ABS cooperative scheduling.

\smallskip
$\bullet$ \textit{Translation of ABS \code{await} statement on futures.}
Consider this ABS snippet:
\lstset{ numberstyle=\tiny, stepnumber=1, numbersep=2pt, basicstyle=\ttfamily\scriptsize, keywordstyle=\bfseries,
    showstringspaces=false}
\begin{lstlisting}
Fut<Bool> ready = server!start(); (1)
await ready?;                     (2)
\end{lstlisting}
We translate the \code{await} statement with a ProActive primitive, \code{getFutureValue}, that forces a wait-by-necessity on the passed future, as follows:
\begin{lstlisting}
PAFuture.getFutureValue(ready);   (2)
\end{lstlisting}
The issue here is that the \code{getFutureValue} primitive is blocking. With no further configuration, no other request would be executed in this COG until the future is resolved, which is not the expected behavior. 
In ProActive multiactive objects, a way to control what happens when a thread switches in wait-by-necessity is to specify the kind of thread limit (in addition to the thread number) that is used by the considered multiactive object: a hard limit restricts the total number of threads whereas a soft limit only restricts the number of threads that are active (not in wait-by-necessity).
Thus, in order to achieve the desired request scheduling, we configure the COG class and its \code{execute} method with multiactive object annotations as follows:
\begin{figure}[!h]
	\setlength\abovecaptionskip{0.25mm}
	\lstset{ numberstyle=\tiny, stepnumber=1, numbersep=2pt, basicstyle=\ttfamily\scriptsize, keywordstyle=\bfseries,
    showstringspaces=false,
    deletekeywords={true, false, public, class},
    morekeywords={@DefineThreadConfig,@Group,@MemberOf}}
\begin{lstlisting}
@DefineGroups({
  @Group(name="scheduling", selfCompatible=true)
})
@DefineThreadConfig(threadPoolSize=1, hardLimit=false)
public class COG {
  ...
  @MemberOf("scheduling")
  public ABSValue execute(UUID objectID, String methodName, ABSType[] args) {
  ...
  }
  ...
}
\end{lstlisting}
\end{figure}
A particular group of requests named \code{scheduling} is declared as \code{selfCompatible}, so that several requests of this group are allowed to execute in parallel.
The \code{execute} method is put in the \code{scheduling} group.
Finally, an instance of COG has a thread limit of 1 (\code{threadPoolSize = 1}), and this limit is not a hard limit (\code{hardLimit = false}). So there can exist only one active thread at a time in a COG multiactive object, and, since they are compatible, an \code{execute} request is allowed to be executed when another \code{execute} request is in wait-by-necessity. Consequently, this annotation configuration leads to a similar scheduling as ABS
	
\smallskip
$\bullet$ \textit{Translation of ABS \code{get} statement.}
The translation of the ABS \code{get} statement would have been straightforward if we had not configured the COG class for the translation of the \code{await} statement. Indeed, by doing so, we have disabled the blocking aspect of the ProActive \code{getFutureValue} primitive. 
Consequently, what is required to translate the \code{get} statement is to temporarily go back to the initial behavior of the ProActive \code{getFutureValue} primitive (like without annotations).
To do that, we temporarily set a hard limit, just for the time the future is waited, so that no other thread can start or resume a request. An ABS \code{get} statement like in \code{ready.get} is translated in ProActive like this:
\begin{lstlisting}
getCOG().switchHardLimit(true);
PAFuture.getFutureValue(ready);  
getCOG().switchHardLimit(false);
\end{lstlisting}
The call to the COG is synchronous since the retrieved COG is the local one, and therefore, we are sure that the limit is switched when executing the next line of code. This way the semantics of \code{get} is preserved in the ProActive translation.

\smallskip
$\bullet$ \textit{Translation of ABS \code{await} statement on conditions.}
Another usage of the ABS \code{await} statement is to use it followed by a condition. For translating this kind of \code{await}, we wrap the condition evaluation in a method call that return a future and we synchronize on it with a \code{getFutureValue} call. More precisely, for each such condition, we generate a corresponding method. Then, we translate the \code{await} statement by an asynchronous call to a generic \code{awaitCondition} method of the COG class
giving it as parameter the current object, the generated method name corresponding to the condition, and the condition members as parameters if they are not accessible from the generated method.
As an example, here is a possible ABS guard:
\begin{lstlisting}
await a == 3;
\end{lstlisting}
First, the ProActive backend generates a corresponding method \code{cond7517d1ff7c52} whose purpose is to check whether the method parameter is equal to 3 (since the second member is constant).
Then, the ABS \code{await} statement is translated into:
\begin{lstlisting}
PAFuture.getFutureValue(
    this.getCog().awaitCondition(this.getId(), "cond7517d1ff7c52", a));
\end{lstlisting}
The \code{awaitCondition} call executes by reflection the method \code{cond7517d1ff7c52} on the object retrieved with the given identifier, passing the parameter \code{a}.
In the annotations on the COG class, we create a new self compatible group of requests to gather \code{awaitCondition} requests and we increase the global thread limit in order to allow several conditions to run in parallel. To be sure that the execution thread is not taken by condition execution, we reserve one thread only for the \code{scheduling} group through an optional parameter of the \code{@Group} annotation.  
So in fact we have a clear separation between the single thread used by the \code{scheduling} group, and the threads used by the \code{waiting} group.
The COG class is thus augmented with new annotations, as follows:
	\setlength\abovecaptionskip{0.25mm}
	\lstset{ numberstyle=\tiny, stepnumber=1, numbersep=2pt, basicstyle=\ttfamily\scriptsize, keywordstyle=\bfseries,
    showstringspaces=false,
    deletekeywords={true, false, public, class},
    morekeywords={@Compatible,@Group,@MemberOf,minThreads,maxThreads,threadPoolSize}}
\begin{lstlisting}
@DefineGroups({
  @Group(name="scheduling", selfCompatible=true, minThreads=1),
  @Group(name="waiting", selfCompatible=true)
})
@DefineRules({
    @Compatible({"scheduling", "waiting"}),
})
@DefineThreadConfig(threadPoolSize=10, hardLimit=false)
public class COG {
  ...
  @MemberOf("scheduling")
  public ABSValue execute(UUID objectID, String methodName, ABSType[] args) {
  ...
  }
  @MemberOf("waiting")
  public ABSType awaitCondition(
      UUID objectID, String methodName, ABSType[] args, Class<?>[] args) {
    ...
  }
  ...
}
\end{lstlisting}

In conclusion, all ABS constructs are sustained by the ProActive backend. We have proven the translation to be correct. For that, we have used ASP, the calculus of ProActive, with multiactive objects extensions, and we have showed that the ASP translation simulates all the rules of ABS semantics, and that all translated ASP configurations correspond to a valid ABS execution. in addition, we have performed two experimental evaluations that show that (i) the ProActive backend speeds up the execution of ABS programs in a distributed environment, and (ii) that the overhead introduced by the translation is always kept under 10\%.



\subsection{Encore}
explicit bytecode operations?
particular accent on data sharing since lots of care has been put is designing an efficient data sharing in Encore.

Encore language implementation consists of two major components, a
Source-to-source compiler (from Encore to C) implemented in Haskell, and the
runtime system, which is based on the same runtime (implemented in C) used by
Pony.

\paragraph{Thread creation and scheduling}

On system start-up, the same number of schedulers are created as the number of
physical cores on the machine unless specified otherwise on the command line.
Each active object in Encore is assigned to an Encore thread (green thread),
which provides thread-of-control for the active object so that it could process
messages in the mailbox. Each scheduler is mapped to an OS thread, and it runs
in a loop of scheduling active objects until the whole program (system)
terminates. Each scheduler owns an active object queue, and in each iteration of
the loop, it performs three procedures. Firstly, pop an active object from the
beginning of the queue. Secondly, hand over the control to the active object so
that it could process messages in the mailbox if any. The active object can only
process one message in this step to ensure fairness. Thirdly, depending on if an
message is indeed processed in previous step, the active object is pushed to the
end of the queue. In the second step, new active objects could be created, and
they are pushed to the end of queue belonging to the current scheduler as well.
Active objects propagates across schedulers because of work stealing, which
tries to achieve load-balancing, and happens whenever a scheduler runs out of
active objects.

\paragraph{Data sharing}

When data (active and passive objects) is shared in Encore, no copying is
performed, so sharing large objects in Encore poses no performance issues. Due
to this particular way of implementing sharing, sharing mutable passive objects
naively could introduce data race. Active objects are not subject to this
problem, for they have thread-of-control internally. Mutable passive objects are
immune of this problem for oblivious reasons. Therefore, the most interesting
case is sharing mutable passive objects. Under capability system, a mutable
passive object could be of kind locked so that sharing it would not result into
data race. In a slightly more advanced usage scenario, we might want to share
part of the mutable passive object so that multiple active objects could work on
different part of the same passive object concurrently. The capability system is
work-in-progress, and not available in the compiler currently.

\subsection{Erlang backend for Rebeca}
\TODO{see if Marjan and ehsan want to put something in this section}	


\section{Lessons Learned and Conclusion}

%\input{survey-parts/introduction.tex}
%\input{survey-parts/example.tex}
%\input{survey-parts/conclusion.tex}

% Appendix
%\appendix
%\section*{APPENDIX}
%\setcounter{section}{1}
%In this appendix,...

%\appendixhead{ZHOU}

% Acknowledgments
%\begin{acks}
%The authors would like to thank Dr. Maura Turolla of Telecom
%Italia for providing specifications about the application scenario.
%\end{acks}

% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{2015-active-objects-survey,biblio,envisage}
                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012

% History dates
%\received{February 2007}{March 2009}{June 2009}

% Electronic Appendix
%\elecappendix

%\medskip

%\section{This is an example of Appendix section head}

\end{document}
% End of v2-acmsmall-sample.tex (March 2012) - Gerry Murray, ACM



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
